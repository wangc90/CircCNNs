{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb73677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "from torchmetrics.classification import F1Score\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "### import Dataset prepartion and model training classes from BS_LS_scripts folder\n",
    "sys.path.insert(1, '/home/wangc90/circRNA/circRNA_Data/BS_LS_scripts/')\n",
    "from BS_LS_DataSet import BS_LS_DataSet_Prep, RCM_Score\n",
    "from BS_LS_Training_Base_models_0 import Objective, Objective_CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e6b2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCM_optuna_flanking(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the RCM score distribution of the flanking introns\n",
    "    '''\n",
    "    def __init__(self, trial):\n",
    "        \n",
    "        super(RCM_optuna_flanking, self).__init__()\n",
    "        \n",
    "        # convlayer 1\n",
    "        self.out_channel1 = trial.suggest_categorical('flanking_out_channel1', [128, 256, 512])\n",
    "#         self.out_channel1 = 128\n",
    "\n",
    "#         kernel_size1 = 5\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=5, out_channels=self.out_channel1,\\\n",
    "                               kernel_size=5, stride=5, padding=0)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "        \n",
    "        self.out_channel2 = trial.suggest_categorical('flanking_out_channel2', [128, 256, 512])\n",
    "#         self.out_channel2 = 32\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2,\\\n",
    "                               kernel_size=5, stride=5, padding=0)\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "        \n",
    "        self.conv2_out_dim = 5\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class RCM_optuna_upper(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the RCM score distribution of the upper introns\n",
    "    '''\n",
    "    def __init__(self, trial):\n",
    "        \n",
    "        super(RCM_optuna_upper, self).__init__()\n",
    "        \n",
    "        # convlayer 1\n",
    "        self.out_channel1 = trial.suggest_categorical('upper_out_channel1', [128, 256, 512])\n",
    "#         self.out_channel1 = 512\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=5, out_channels=self.out_channel1,\\\n",
    "                               kernel_size=5, stride=5, padding=0)\n",
    "        \n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "        \n",
    "        self.out_channel2 = trial.suggest_categorical('upper_out_channel2', [128, 256, 512])\n",
    "#         self.out_channel2 = 64\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2,\\\n",
    "                               kernel_size=5, stride=5, padding=0)\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "        self.conv2_out_dim = 5\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class RCM_optuna_lower(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the RCM score distribution of the lower introns\n",
    "    '''\n",
    "    def __init__(self, trial):\n",
    "        \n",
    "        super(RCM_optuna_lower, self).__init__()\n",
    "        \n",
    "        # convlayer 1\n",
    "        self.out_channel1 = trial.suggest_categorical('lower_out_channel1', [128, 256, 512])\n",
    "#         self.out_channel1 = 512\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=5, out_channels=self.out_channel1,\\\n",
    "                               kernel_size=5, stride=5, padding=0)\n",
    "        \n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "        self.out_channel2 = trial.suggest_categorical('lower_out_channel2', [128, 256, 512])\n",
    "#         self.out_channel2 = 512\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2,\\\n",
    "                               kernel_size=5, stride=5, padding=0)\n",
    "        \n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "        self.conv2_out_dim = 5\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "class RCM_optuna_concate(nn.Module):\n",
    "    ''''\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, trial):\n",
    "        \n",
    "        super(RCM_optuna_concate, self).__init__()\n",
    "\n",
    "        ### cnn for the flanking rcm scores\n",
    "        self.cnn_flanking = RCM_optuna_flanking(trial)\n",
    "\n",
    "        self.flanking_out_dim = self.cnn_flanking.conv2_out_dim\n",
    "        self.flanking_out_channel = self.cnn_flanking.out_channel2\n",
    "#         print(f'flanking out dim: {self.flanking_out_dim}, flanking out channel {self.flanking_out_channel}')\n",
    "        \n",
    "        ### cnn for the upper rcm scores\n",
    "        self.cnn_upper = RCM_optuna_upper(trial)\n",
    "\n",
    "        self.upper_out_dim = self.cnn_upper.conv2_out_dim\n",
    "        self.upper_out_channel = self.cnn_upper.out_channel2\n",
    "#         print(f'upper_out_dim: {self.upper_out_dim}, upper_out_channel {self.upper_out_channel}')\n",
    "        \n",
    "        ### cnn for the lower rcm scores\n",
    "        self.cnn_lower = RCM_optuna_lower(trial)\n",
    "\n",
    "        self.lower_out_dim = self.cnn_lower.conv2_out_dim\n",
    "        self.lower_out_channel = self.cnn_lower.out_channel2\n",
    "#         print(f'lower_out_dim: {self.lower_out_dim}, lower_out_channel {self.lower_out_channel}')\n",
    "        \n",
    "\n",
    "        self.fc1_input_dim = self.flanking_out_dim * self.flanking_out_channel + \\\n",
    "                             self.upper_out_dim * self.upper_out_channel + \\\n",
    "                             self.lower_out_dim * self.lower_out_channel\n",
    "\n",
    "#         print(f'fc1_input_dim: {self.fc1_input_dim}')\n",
    "        \n",
    "        \n",
    "        self.fc1_out = trial.suggest_categorical('concat_fc1_out', [128, 256, 512])\n",
    "#         self.fc1_out = 512\n",
    "    \n",
    "        # add the rcm feature dimension here as well (5*5+2)*3+2 = 83\n",
    "        self.fc1 = nn.Linear(self.fc1_input_dim, self.fc1_out)\n",
    "        \n",
    "        self.fc1_bn = nn.BatchNorm1d(self.fc1_out)\n",
    "\n",
    "        dropout_rate_fc1 = trial.suggest_categorical(\"concat_dropout_rate_fc1\",  [0, 0.1, 0.2, 0.4])\n",
    "        self.drop_nn1 = nn.Dropout(p=dropout_rate_fc1)\n",
    "\n",
    "        # fc layer2\n",
    "        # use dimension output with nn.CrossEntropyLoss()\n",
    "        self.fc2_out = trial.suggest_categorical('concat_fc2_out', [4, 8, 16, 32])\n",
    "#         self.fc2_out = 8\n",
    "        self.fc2 = nn.Linear(self.fc1_out, self.fc2_out)\n",
    "\n",
    "        self.fc2_bn = nn.BatchNorm1d(self.fc2_out)\n",
    "\n",
    "        dropout_rate_fc2 = trial.suggest_categorical(\"concat_dropout_rate_fc2\",[0, 0.1, 0.2, 0.4])\n",
    "    \n",
    "        self.drop_nn2 = nn.Dropout(p=dropout_rate_fc2)\n",
    "\n",
    "        self.fc3 = nn.Linear(self.fc2_out, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, rcm_flanking, rcm_upper, rcm_lower):\n",
    "        \n",
    "        x1 = self.cnn_flanking(rcm_flanking)\n",
    "\n",
    "        x2 = self.cnn_upper(rcm_upper)\n",
    "        \n",
    "        x3 = self.cnn_lower(rcm_lower)\n",
    "        \n",
    "        x = torch.cat((x1,x2,x3), dim=1)\n",
    "    \n",
    "        # feed the concatenated feature to fc1\n",
    "        out = self.fc1(x)\n",
    "        out = self.drop_nn1(torch.relu(self.fc1_bn(out)))\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop_nn2(torch.relu(self.fc2_bn(out)))\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60bf982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcm_flankingWithin_small_windows_optuna(num_trial):\n",
    "    \n",
    "    ## specify different kmer length to get the training data of the rcm score for that kmer \n",
    "    ### just change this number to 10, 20, 40 and 80 to get the model performance for different kmer length\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "\n",
    "    ### where to save the 3-fold CV validation acc based on the rcm score and mlp\n",
    "\n",
    "    val_acc_folder = f'/home/wangc90/circRNA/circRNA_Data/model_outputs/rcm_flankingWithin_small_windows/9000/val_acc_cv3'\n",
    "    ### wehre to save the detailed optuna results\n",
    "    optuna_folder = f'/home/wangc90/circRNA/circRNA_Data/model_outputs/rcm_flankingWithin_small_windows/9000/optuna'\n",
    "    \n",
    "    \n",
    "    BS_LS_coordinates_path = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/updated_data/BS_LS_coordinates_final.csv'\n",
    "    hg19_seq_dict_json_path = '/home/wangc90/circRNA/circRNA_Data/hg19_seq/hg19_seq_dict.json'\n",
    "    flanking_dict_folder = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/flanking_dicts/'\n",
    "    bs_ls_dataset = BS_LS_DataSet_Prep(BS_LS_coordinates_path=BS_LS_coordinates_path,\n",
    "                                   hg19_seq_dict_json_path=hg19_seq_dict_json_path,\n",
    "                                   flanking_dict_folder=flanking_dict_folder,\n",
    "                                   flanking_junction_bps=100,\n",
    "                                   flanking_intron_bps=5000,\n",
    "                                   training_size=9000)\n",
    "\n",
    "\n",
    "    ## generate the junction and flanking intron dict\n",
    "    bs_ls_dataset.get_junction_flanking_intron_seq()\n",
    "\n",
    "    train_key_1, _, test_keys = bs_ls_dataset.get_train_test_keys()\n",
    "\n",
    "    rcm_scores_folder = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/flanking_dicts/rcm_scores/'\n",
    "\n",
    "    ### try with rcm features\n",
    "    _, _, train_torch_flanking_rcm, train_torch_upper_rcm,\\\n",
    "    train_torch_lower_rcm, train_torch_labels = bs_ls_dataset.seq_to_tensor(data_keys=train_key_1,\\\n",
    "                                                                            rcm_folder=rcm_scores_folder,\\\n",
    "                                                                            is_rcm=True,\\\n",
    "                                                                            is_upper_lower_concat=False)\n",
    "    \n",
    "#     print(train_torch_flanking_rcm.shape)\n",
    "\n",
    "    RCM_kmer_Score_dataset = RCM_Score(flanking_only=False,\n",
    "                                       flanking_rcm=train_torch_flanking_rcm,\\\n",
    "                                       upper_rcm=train_torch_upper_rcm,\\\n",
    "                                       lower_rcm=train_torch_lower_rcm,\\\n",
    "                                       label=train_torch_labels)\n",
    "    \n",
    "    \n",
    "    print(len(RCM_kmer_Score_dataset))\n",
    "    \n",
    "    study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=1, n_startup_trials=10),\n",
    "                                direction='maximize')\n",
    "\n",
    "\n",
    "    study.optimize(Objective_CV(cv=3, model= RCM_optuna_concate, \n",
    "                                dataset=RCM_kmer_Score_dataset,\n",
    "                                val_acc_folder=val_acc_folder), n_trials=num_trial, gc_after_trial=True)\n",
    "\n",
    "\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    with open(optuna_folder+'/optuna.txt', 'a') as f:\n",
    "        f.write(\"Study statistiqcs: \\n\")\n",
    "        f.write(f\"Number of finished trials: {len(study.trials)}\\n\")\n",
    "        f.write(f\"Number of pruned trials: {len(pruned_trials)}\\n\")\n",
    "        f.write(f\"Number of complete trials: {len(complete_trials)}\\n\")\n",
    "\n",
    "        f.write(\"Best trial:\\n\")\n",
    "        trial = study.best_trial\n",
    "        f.write(f\"Value: {trial.value}\\n\")\n",
    "        f.write(\"Params:\\n\")\n",
    "        for key, value in trial.params.items():\n",
    "            f.write(f\"{key}:{value}\\n\")\n",
    "\n",
    "    df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete','duration','number'], axis=1)\n",
    "    df.to_csv(optuna_folder + '/optuna.csv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98662399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 19:16:10,265]\u001b[0m A new study created in memory with name: no-name-d5202fcd-6402-478c-8690-052784fd2582\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr5|138837130|138837392|- has N in the extracted junctions, belongs to BS\n",
      "There are 0 overlapped flanking sequence from BS and LS  \n",
      "There are 7 repeated BS sequences\n",
      "There are 2 repeated LS sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 19:18:25,015]\u001b[0m A new study created in memory with name: no-name-ca7b90a1-7a22-49e8-957d-fca2926808d5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "fold 1, epoch 20, val loss 8.767366170883179 val accuracy 0.6003\n",
      "fold 1, epoch 40, val loss 9.889778137207031 val accuracy 0.5938\n",
      "fold 1, epoch 60, val loss 11.187600076198578 val accuracy 0.605\n",
      "fold 1, epoch 80, val loss 12.18494176864624 val accuracy 0.6042\n",
      "fold 1, epoch 100, val loss 13.006317138671875 val accuracy 0.6037\n",
      "fold 1, epoch 120, val loss 14.115652084350586 val accuracy 0.6115\n",
      "fold 2, epoch 20, val loss 8.459560692310333 val accuracy 0.5913\n",
      "fold 2, epoch 40, val loss 9.164281249046326 val accuracy 0.6097\n",
      "fold 2, epoch 60, val loss 10.19625872373581 val accuracy 0.6105\n",
      "fold 2, epoch 80, val loss 11.65113478899002 val accuracy 0.6088\n",
      "fold 2, epoch 100, val loss 12.778429448604584 val accuracy 0.6045\n",
      "fold 2, epoch 120, val loss 13.454310774803162 val accuracy 0.611\n",
      "fold 3, epoch 20, val loss 8.369351089000702 val accuracy 0.599\n",
      "fold 3, epoch 40, val loss 9.264171540737152 val accuracy 0.6073\n",
      "fold 3, epoch 60, val loss 10.234699130058289 val accuracy 0.6147\n",
      "fold 3, epoch 80, val loss 11.46654999256134 val accuracy 0.6058\n",
      "fold 3, epoch 100, val loss 12.828123331069946 val accuracy 0.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 19:33:53,245]\u001b[0m Trial 0 finished with value: 0.6095 and parameters: {'lr': 0.0002707952072734182, 'l2_lambda': 2.7527204568094844e-08, 'batch_size': 512, 'epochs': 120, 'flanking_out_channel1': 128, 'flanking_out_channel2': 256, 'upper_out_channel1': 256, 'upper_out_channel2': 256, 'lower_out_channel1': 128, 'lower_out_channel2': 256, 'concat_fc1_out': 256, 'concat_dropout_rate_fc1': 0.1, 'concat_fc2_out': 4, 'concat_dropout_rate_fc2': 0.1}. Best is trial 0 with value: 0.6095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3, epoch 120, val loss 13.603398978710175 val accuracy 0.606\n",
      "fold 1, epoch 20, val loss 7.991870641708374 val accuracy 0.5975\n",
      "fold 1, epoch 40, val loss 7.937642574310303 val accuracy 0.62\n",
      "fold 1, epoch 60, val loss 8.218115329742432 val accuracy 0.6282\n",
      "fold 1, epoch 80, val loss 8.434654235839844 val accuracy 0.6328\n",
      "fold 1, epoch 100, val loss 8.691682279109955 val accuracy 0.6355\n",
      "fold 1, epoch 120, val loss 8.917702615261078 val accuracy 0.638\n",
      "fold 2, epoch 20, val loss 7.986864984035492 val accuracy 0.5958\n",
      "fold 2, epoch 40, val loss 7.981665551662445 val accuracy 0.6162\n",
      "fold 2, epoch 60, val loss 8.038096487522125 val accuracy 0.625\n",
      "fold 2, epoch 80, val loss 8.31163775920868 val accuracy 0.6267\n",
      "fold 2, epoch 100, val loss 8.401546657085419 val accuracy 0.6352\n",
      "fold 2, epoch 120, val loss 8.625715017318726 val accuracy 0.6393\n",
      "fold 3, epoch 20, val loss 7.910773158073425 val accuracy 0.6078\n",
      "fold 3, epoch 40, val loss 7.874687671661377 val accuracy 0.6257\n",
      "fold 3, epoch 60, val loss 7.970572292804718 val accuracy 0.6357\n",
      "fold 3, epoch 80, val loss 8.171089887619019 val accuracy 0.6455\n",
      "fold 3, epoch 100, val loss 8.367092907428741 val accuracy 0.6468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 19:54:34,680]\u001b[0m Trial 1 finished with value: 0.6403666666666666 and parameters: {'lr': 1.1769135760472114e-05, 'l2_lambda': 6.731526994689957e-08, 'batch_size': 512, 'epochs': 120, 'flanking_out_channel1': 256, 'flanking_out_channel2': 128, 'upper_out_channel1': 512, 'upper_out_channel2': 256, 'lower_out_channel1': 512, 'lower_out_channel2': 512, 'concat_fc1_out': 512, 'concat_dropout_rate_fc1': 0.2, 'concat_fc2_out': 32, 'concat_dropout_rate_fc2': 0}. Best is trial 1 with value: 0.6403666666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3, epoch 120, val loss 8.554411768913269 val accuracy 0.6438\n",
      "fold 1, epoch 20, val loss 9.260818600654602 val accuracy 0.5008\n",
      "fold 2, epoch 20, val loss 8.483006954193115 val accuracy 0.503\n",
      "fold 3, epoch 20, val loss 7.932726442813873 val accuracy 0.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 19:58:47,097]\u001b[0m Trial 2 finished with value: 0.5372 and parameters: {'lr': 0.00010249135451343229, 'l2_lambda': 3.814336585151029e-09, 'batch_size': 512, 'epochs': 30, 'flanking_out_channel1': 128, 'flanking_out_channel2': 512, 'upper_out_channel1': 128, 'upper_out_channel2': 256, 'lower_out_channel1': 512, 'lower_out_channel2': 256, 'concat_fc1_out': 512, 'concat_dropout_rate_fc1': 0.1, 'concat_fc2_out': 4, 'concat_dropout_rate_fc2': 0}. Best is trial 1 with value: 0.6403666666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1, epoch 20, val loss 66.05003499984741 val accuracy 0.5653\n",
      "fold 1, epoch 40, val loss 75.09051591157913 val accuracy 0.5693\n",
      "fold 1, epoch 60, val loss 90.38586366176605 val accuracy 0.5793\n",
      "fold 1, epoch 80, val loss 109.08717918395996 val accuracy 0.5748\n",
      "fold 1, epoch 100, val loss 133.3338109254837 val accuracy 0.58\n",
      "fold 1, epoch 120, val loss 152.48341155052185 val accuracy 0.5823\n",
      "fold 2, epoch 20, val loss 66.69586086273193 val accuracy 0.568\n",
      "fold 2, epoch 40, val loss 75.79477542638779 val accuracy 0.573\n",
      "fold 2, epoch 60, val loss 92.48435878753662 val accuracy 0.5708\n",
      "fold 2, epoch 80, val loss 103.93229156732559 val accuracy 0.5858\n",
      "fold 2, epoch 100, val loss 122.47710663080215 val accuracy 0.587\n",
      "fold 2, epoch 120, val loss 134.82183331251144 val accuracy 0.5883\n",
      "fold 3, epoch 20, val loss 66.49056994915009 val accuracy 0.5587\n",
      "fold 3, epoch 40, val loss 78.00380426645279 val accuracy 0.5643\n",
      "fold 3, epoch 60, val loss 90.74130153656006 val accuracy 0.5638\n",
      "fold 3, epoch 80, val loss 110.16517305374146 val accuracy 0.565\n",
      "fold 3, epoch 100, val loss 132.05536752939224 val accuracy 0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 20:35:14,633]\u001b[0m Trial 3 finished with value: 0.5794333333333334 and parameters: {'lr': 2.195784179788312e-05, 'l2_lambda': 8.053682535161848e-08, 'batch_size': 64, 'epochs': 120, 'flanking_out_channel1': 128, 'flanking_out_channel2': 256, 'upper_out_channel1': 512, 'upper_out_channel2': 512, 'lower_out_channel1': 128, 'lower_out_channel2': 128, 'concat_fc1_out': 128, 'concat_dropout_rate_fc1': 0.4, 'concat_fc2_out': 8, 'concat_dropout_rate_fc2': 0.1}. Best is trial 1 with value: 0.6403666666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3, epoch 120, val loss 155.81408166885376 val accuracy 0.5677\n",
      "fold 1, epoch 20, val loss 205.1455046236515 val accuracy 0.6022\n",
      "fold 2, epoch 20, val loss 213.01728823781013 val accuracy 0.6003\n",
      "fold 3, epoch 20, val loss 212.91790837049484 val accuracy 0.5953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 20:51:25,567]\u001b[0m Trial 4 finished with value: 0.6030666666666666 and parameters: {'lr': 6.97662779020888e-05, 'l2_lambda': 7.244795099486098e-09, 'batch_size': 32, 'epochs': 30, 'flanking_out_channel1': 256, 'flanking_out_channel2': 512, 'upper_out_channel1': 128, 'upper_out_channel2': 256, 'lower_out_channel1': 256, 'lower_out_channel2': 512, 'concat_fc1_out': 128, 'concat_dropout_rate_fc1': 0.1, 'concat_fc2_out': 8, 'concat_dropout_rate_fc2': 0}. Best is trial 1 with value: 0.6403666666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1, epoch 20, val loss 16.149396121501923 val accuracy 0.6317\n",
      "fold 1, epoch 40, val loss 16.649711668491364 val accuracy 0.6427\n",
      "fold 1, epoch 60, val loss 17.839934170246124 val accuracy 0.6542\n",
      "fold 1, epoch 80, val loss 19.328479409217834 val accuracy 0.6488\n",
      "fold 1, epoch 100, val loss 21.233786523342133 val accuracy 0.6518\n",
      "fold 1, epoch 120, val loss 22.587694883346558 val accuracy 0.656\n",
      "fold 2, epoch 20, val loss 15.816957175731659 val accuracy 0.6382\n",
      "fold 2, epoch 40, val loss 15.899355947971344 val accuracy 0.6475\n",
      "fold 2, epoch 60, val loss 16.93992990255356 val accuracy 0.6495\n",
      "fold 2, epoch 80, val loss 18.384577929973602 val accuracy 0.6562\n",
      "fold 2, epoch 100, val loss 20.291907966136932 val accuracy 0.6532\n",
      "fold 2, epoch 120, val loss 21.904040694236755 val accuracy 0.6497\n",
      "fold 3, epoch 20, val loss 15.428453207015991 val accuracy 0.6323\n",
      "fold 3, epoch 40, val loss 15.60856419801712 val accuracy 0.6473\n",
      "fold 3, epoch 60, val loss 15.795445322990417 val accuracy 0.6572\n",
      "fold 3, epoch 80, val loss 17.08218604326248 val accuracy 0.6547\n",
      "fold 3, epoch 100, val loss 18.329721331596375 val accuracy 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 21:14:25,268]\u001b[0m Trial 5 finished with value: 0.6523 and parameters: {'lr': 6.180965726328772e-05, 'l2_lambda': 1.3313985083188563e-09, 'batch_size': 256, 'epochs': 120, 'flanking_out_channel1': 128, 'flanking_out_channel2': 128, 'upper_out_channel1': 512, 'upper_out_channel2': 256, 'lower_out_channel1': 512, 'lower_out_channel2': 512, 'concat_fc1_out': 512, 'concat_dropout_rate_fc1': 0.1, 'concat_fc2_out': 8, 'concat_dropout_rate_fc2': 0.2}. Best is trial 5 with value: 0.6523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3, epoch 120, val loss 20.20127445459366 val accuracy 0.6512\n",
      "fold 1, epoch 20, val loss 142.39729177951813 val accuracy 0.5817\n",
      "fold 1, epoch 40, val loss 125.321537733078 val accuracy 0.5908\n",
      "fold 1, epoch 60, val loss 162.7306448817253 val accuracy 0.5965\n",
      "fold 1, epoch 80, val loss 166.13279259204865 val accuracy 0.5918\n",
      "fold 1, epoch 100, val loss 178.8334949016571 val accuracy 0.596\n",
      "fold 1, epoch 120, val loss 186.93602204322815 val accuracy 0.592\n",
      "fold 2, epoch 20, val loss 130.93735945224762 val accuracy 0.6012\n",
      "fold 2, epoch 40, val loss 154.3684406876564 val accuracy 0.6097\n",
      "fold 2, epoch 60, val loss 155.02005279064178 val accuracy 0.5992\n",
      "fold 2, epoch 80, val loss 151.43384152650833 val accuracy 0.6012\n",
      "fold 2, epoch 100, val loss 161.47147917747498 val accuracy 0.6033\n",
      "fold 2, epoch 120, val loss 172.37312197685242 val accuracy 0.5992\n",
      "fold 3, epoch 20, val loss 137.87380999326706 val accuracy 0.5995\n",
      "fold 3, epoch 40, val loss 172.58563655614853 val accuracy 0.6062\n",
      "fold 3, epoch 60, val loss 148.40562629699707 val accuracy 0.5973\n",
      "fold 3, epoch 80, val loss 178.064000248909 val accuracy 0.5913\n",
      "fold 3, epoch 100, val loss 188.02984684705734 val accuracy 0.5992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-22 21:49:29,347]\u001b[0m Trial 6 finished with value: 0.5943999999999999 and parameters: {'lr': 0.0002571152733227137, 'l2_lambda': 4.291354366012778e-07, 'batch_size': 64, 'epochs': 120, 'flanking_out_channel1': 256, 'flanking_out_channel2': 128, 'upper_out_channel1': 512, 'upper_out_channel2': 128, 'lower_out_channel1': 128, 'lower_out_channel2': 128, 'concat_fc1_out': 512, 'concat_dropout_rate_fc1': 0, 'concat_fc2_out': 32, 'concat_dropout_rate_fc2': 0}. Best is trial 5 with value: 0.6523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3, epoch 120, val loss 195.59751397371292 val accuracy 0.592\n",
      "fold 1, epoch 20, val loss 160.45536828041077 val accuracy 0.5842\n",
      "fold 1, epoch 40, val loss 188.76232302188873 val accuracy 0.5902\n",
      "fold 1, epoch 60, val loss 218.50530874729156 val accuracy 0.5893\n",
      "fold 1, epoch 80, val loss 229.36381816864014 val accuracy 0.5865\n",
      "fold 1, epoch 100, val loss 241.5366997718811 val accuracy 0.5908\n",
      "fold 1, epoch 120, val loss 239.01858699321747 val accuracy 0.5762\n",
      "fold 1, epoch 140, val loss 229.88340187072754 val accuracy 0.6007\n"
     ]
    }
   ],
   "source": [
    "rcm_flankingWithin_small_windows_optuna(num_trial=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fee5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
