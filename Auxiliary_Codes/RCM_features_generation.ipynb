{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5dd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from itertools import product\n",
    "import ray\n",
    "from itertools import combinations\n",
    "os.environ['RAY_worker_register_timeout_seconds'] = '60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e651f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCS_visualization(seq1, seq2):\n",
    "    '''\n",
    "        This function takes in two sequence and print out the first seq\n",
    "        in 5'-3' direction and second seq in 3'-5' direction to visualize \n",
    "        the RCS between them\n",
    "    '''\n",
    "    complement_dict = {'A':'T', 'G':'C', 'T':'A', 'C':'G', 'N': 'N'}\n",
    "    reversed_seq2 = seq2[::-1]\n",
    "    marker = ''\n",
    "    for i, j in enumerate(seq1):\n",
    "        if j == complement_dict[reversed_seq2[i]]:\n",
    "            marker += '-'\n",
    "        else:\n",
    "            marker += '*'\n",
    "    print(\"5' \" + seq1 + \" 3'\", \"   \" + marker + \"   \", \"3' \" + reversed_seq2 + \" 5'\", sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7228b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ray.remote\n",
    "# class RCS_finder():\n",
    "#     '''\n",
    "#         This is a python class that can find the imperfect reverse complementary sequences (RCS) within\n",
    "#         a intronic sequence ranging from 50bps to 50kbps; it can also find the imperfect RCS of two\n",
    "#         flanking introns each ranging from 50bps to 50kbps.\n",
    "\n",
    "#         input_seq1: the Up flanking intron;\n",
    "#         input_seq2: the Lower flanking intron;\n",
    "#         is_flanking_introns: boolean value indicating whether dealing with two flanking introns\n",
    "#         if is_flanking_introns == False, the input_seq2 will be ignored and only input_seq1 will be used;\n",
    "#         seed_len: seed length for the initial RCS search\n",
    "#         seq_fraction_of_spacer: the minimal portion of the seq length between the two paired seed region\n",
    "#                                 when dealing with one intron (between 0 to 1); set spacer to 0 if\n",
    "#                                 spacer length is not used for filtering;\n",
    "#         allowed_seed_mismatch: allowed the number of mismatch in the seed region: default is 1 (i.e., 2 score)\n",
    "#         allowed_max_mismatch: allowed total number of mismatches in the RCS searching: default is 5 (i.e., 10 score)\n",
    "#         seq_partion: partion of sequence for kmer distribution calculation: (e.g., 3: 3 by 3 grids)\n",
    "#     '''\n",
    "\n",
    "#     def __init__(self, key=None, input_seq1=None, input_seq2=None, is_flanking_introns=None, seed_len=None, \\\n",
    "#                  seq_fraction_of_spacer=None, allowed_seed_mismatch=None, allowed_max_mismatch=None,\n",
    "#                  seq_partition=None):\n",
    "#         self.key = key\n",
    "#         self.input_seq1 = input_seq1\n",
    "#         self.input_seq2 = input_seq2\n",
    "#         self.is_flanking_introns = is_flanking_introns\n",
    "#         self.seed_len = seed_len\n",
    "#         self.seq_fraction_of_spacer = seq_fraction_of_spacer\n",
    "#         self.allowed_seed_mismatch = allowed_seed_mismatch\n",
    "#         self.allowed_max_mismatch = allowed_max_mismatch\n",
    "#         self.seq_partition = seq_partition\n",
    "# #         self.num_rcm_kmers = None\n",
    "# #         self.num_rcm_kmers_per_10000_comp = None\n",
    "# #         self.joint_rcm_kmer_dist = None\n",
    "# #         self.valid_subseq_pairs_list = None\n",
    "# #         self.all_possible_subseqs_dict = None\n",
    "# #         self.rcm_summary_stats = None\n",
    "# #         self.interval_combinations = None\n",
    "# #         self.joint_subseq_pair_dist = None\n",
    "\n",
    "#     def base_conversion(self, seq):\n",
    "#         '''\n",
    "#             convert the input sequence into the numerical representation\n",
    "#         '''\n",
    "#         base_mapping = {'A': 1, 'T': -1, 'C': 1j, 'G': -1j, 'N': 0}\n",
    "#         if len(seq) >= 2:\n",
    "#             seq_map = np.array([base_mapping[i] for i in seq])\n",
    "#         else:\n",
    "#             seq_map = base_mapping[seq]\n",
    "#         return seq_map\n",
    "\n",
    "#     def get_sub_seq_score(self, seq):\n",
    "\n",
    "#         '''\n",
    "#             This function starts with a input sequence and return\n",
    "#             the cummulative sum of the subsequence of length min_seq\n",
    "#         '''\n",
    "#         # get the augumented input sequence\n",
    "#         aug_seq = 'N' + seq\n",
    "#         # convert the augumented sequence into the numerical representation\n",
    "#         aug_seq_M = self.base_conversion(aug_seq)\n",
    "#         # get the cumulative sum of the augumented sequence\n",
    "#         aug_seq_cum_M = aug_seq_M.cumsum()\n",
    "#         # get the cumulative sum of the original input sequence\n",
    "#         seq_cum_M = aug_seq_cum_M[1:]\n",
    "#         # get subsequence score with length=self.seed_len\n",
    "#         sub_seq_score = seq_cum_M[self.seed_len - 1:] - aug_seq_cum_M[:len(aug_seq) - self.seed_len]\n",
    "#         return sub_seq_score\n",
    "\n",
    "#     def get_allowed_window_index(self):\n",
    "#         '''\n",
    "#             This function takes in the subseq_scores, and a fraction number (i.e., betwen 0 and 1) and return\n",
    "#             the allowed pair of window index that can be used for further subseqs verification\n",
    "#         '''\n",
    "#         if self.is_flanking_introns:\n",
    "#             # deal with flanking introns\n",
    "#             subseq_score1 = self.get_sub_seq_score(self.input_seq1).astype(np.complex64)\n",
    "#             subseq_score2 = self.get_sub_seq_score(self.input_seq2).astype(np.complex64)\n",
    "\n",
    "#             # put all possible pair-wise subseq addition score in the matrix\n",
    "#             # first subseq as the column, second subseq as the row\n",
    "#             subseq_scores_sum = subseq_score1.reshape((-1, 1)) + subseq_score2.reshape((1, -1))\n",
    "\n",
    "#             # get the sum of the absolute value of imaginary part and real part\n",
    "#             subseq_scores_abs_sum_mat = abs(subseq_scores_sum.imag) + abs(subseq_scores_sum.real)\n",
    "\n",
    "#             # get the index for the pair of subseqs that potentially have at most 1 mismatch (i.e., abs sum <= 2)\n",
    "#             first_window, second_window = np.where(subseq_scores_abs_sum_mat <= self.allowed_seed_mismatch)\n",
    "\n",
    "#             return first_window, second_window\n",
    "#         else:\n",
    "#             # deal with one intron only, use the input_seq1\n",
    "#             subseq_scores = self.get_sub_seq_score(self.input_seq1)\n",
    "\n",
    "#             ### this step is fast\n",
    "#             subseq_scores = subseq_scores.astype(np.complex64)\n",
    "\n",
    "#             #### this step takes about 7 seconds\n",
    "#             # put all possible pair-wise subseq addition score in the matrix\n",
    "#             subseq_scores_sum = subseq_scores.reshape((-1, 1)) + subseq_scores.reshape((1, -1))\n",
    "\n",
    "#             #### this step takes about 11 seconds\n",
    "#             # get the sum of the absolute value of imaginary part and real part\n",
    "#             subseq_scores_abs_sum_mat = abs(subseq_scores_sum.imag) + abs(subseq_scores_sum.real)\n",
    "\n",
    "#             #### this step takes about 9 seconds\n",
    "#             # obtain the lower triangular index including the diagnoal\n",
    "#             tril_index = np.tril_indices(subseq_scores_abs_sum_mat.shape[0])\n",
    "\n",
    "#             #### this step takes about 7 seconds\n",
    "#             # change the lower triangular value to be bigger than 2, thus don't need to filter due to the  matrix symetry\n",
    "#             subseq_scores_abs_sum_mat[tril_index] = self.allowed_seed_mismatch + 1\n",
    "\n",
    "#             #### this step takes about 9 seconds\n",
    "#             # get the index for the pair of subseqs that potentially have at most 1 mismatch (i.e., abs sum <= 2)\n",
    "#             first_window, second_window = np.where(subseq_scores_abs_sum_mat <= self.allowed_seed_mismatch)\n",
    "\n",
    "#             #### this step takes about 0.9 seconds\n",
    "#             # get the window distance for each pair of subseqs\n",
    "#             window_num_diff = second_window - first_window\n",
    "\n",
    "#             #### this step takes about 0.7 seconds\n",
    "#             # get the base pair distance for each pair of subseqs # 10 is the default arm length\n",
    "#             spacer = window_num_diff - self.seed_len\n",
    "\n",
    "#             ### this step takes about 0.3 seconds; set fraction_of_spacer at least to 0 to\n",
    "#             ### avoid the overlapping windows\n",
    "#             # base pair distance for each pair of subseqs at least half the total seq length\n",
    "#             allowed_index = (spacer >= len(self.input_seq1) * self.seq_fraction_of_spacer)\n",
    "\n",
    "#             ### these two steps take about 0.6 seconds\n",
    "#             # get the allowed window index\n",
    "#             allowed_first_window = first_window[allowed_index]\n",
    "#             allowed_second_window = second_window[allowed_index]\n",
    "\n",
    "#             return allowed_first_window, allowed_second_window\n",
    "\n",
    "#     def subseq_validity_check(self):\n",
    "\n",
    "#         '''\n",
    "#             This function is used to check wether the subseq pairs identified in get_allowed_window_index function\n",
    "#             is valid or not by calling the check_valid_subseq_pairs function,\n",
    "#             This function also return the relative location of the valid rcm kmers as well as number of\n",
    "#             kmers per 10000 comparison\n",
    "#         '''\n",
    "#         first_window, second_window = self.get_allowed_window_index()\n",
    "\n",
    "#         valid_subseq_pairs_list = []\n",
    "\n",
    "#         complement_dict = {'A': 'T', 'G': 'C', 'T': 'A', 'C': 'G', 'N': 'N'}\n",
    "\n",
    "#         ### check to see if dealing with one introns or flanking introns\n",
    "#         if self.is_flanking_introns:\n",
    "#             input_seq1 = self.input_seq1\n",
    "#             input_seq2 = self.input_seq2\n",
    "#         else:\n",
    "#             input_seq1 = self.input_seq1\n",
    "#             input_seq2 = self.input_seq1\n",
    "\n",
    "#         for first_index, second_index in zip(first_window, second_window):\n",
    "\n",
    "#             # set it for each window pair\n",
    "#             seed_mismatch_score = 0\n",
    "\n",
    "#             first_subseq, second_subseq = input_seq1[first_index:self.seed_len + first_index], \\\n",
    "#                                           input_seq2[second_index:self.seed_len + second_index]\n",
    "\n",
    "#             # check for the two ends first to make sure end is matching\n",
    "#             if first_subseq[0] == complement_dict[second_subseq[-1]]:\n",
    "#                 # check the interior subseq\n",
    "#                 for i in range(1, self.seed_len):\n",
    "#                     if first_subseq[i] != complement_dict[second_subseq[-i - 1]]:\n",
    "#                         seed_mismatch_score += 2\n",
    "#                         # if total mismatch already bigger than 2 abort the further checking\n",
    "#                         if seed_mismatch_score > self.allowed_seed_mismatch:\n",
    "#                             break\n",
    "\n",
    "#                 if seed_mismatch_score <= self.allowed_seed_mismatch:\n",
    "#                     valid_subseq_pairs_list.append((first_subseq, first_index, second_subseq, \\\n",
    "#                                                     second_index, seed_mismatch_score))\n",
    "\n",
    "#         ### The following code: extract the rcm kmer location distribution relative\n",
    "#         ### to the corresponding upper or lower intron\n",
    "\n",
    "#         ### create interval list for upper and lower introns based on the upper and lower intron length\n",
    "\n",
    "#         upper_equal_space_list = np.linspace(start=0, stop=len(input_seq1), num=self.seq_partition+1)\n",
    "\n",
    "#         lower_equal_space_list = np.linspace(start=0, stop=len(input_seq2), num=self.seq_partition+1)\n",
    "\n",
    "#         upper_interval_list = []\n",
    "#         lower_interval_list = []\n",
    "\n",
    "#         for i in range(len(upper_equal_space_list) - 1):\n",
    "#             upper_interval = (upper_equal_space_list[i], upper_equal_space_list[i + 1])\n",
    "#             upper_interval_list.append(upper_interval)\n",
    "\n",
    "#         for i in range(len(lower_equal_space_list) - 1):\n",
    "#             lower_interval = (lower_equal_space_list[i], lower_equal_space_list[i + 1])\n",
    "#             lower_interval_list.append(lower_interval)\n",
    "\n",
    "#         ### get the combination of interval from upper and lower introns 5 x 5 interval in this case\n",
    "#         ### if num = 6\n",
    "#         interval_combinations = list(product(upper_interval_list, lower_interval_list))\n",
    "        \n",
    "#         ## save this interval_combinations to self.interval_combinations for the distribution of extended subseq pairs\n",
    "#         self.interval_combinations = interval_combinations\n",
    "        \n",
    "\n",
    "#         ### get the upper and lower rcm kmer position pairs\n",
    "#         upper_lower_rcm_kmer_pos_pairs = []\n",
    "#         for i in valid_subseq_pairs_list:\n",
    "#             upper_lower_rcm_kmer_pos_pairs.append((i[1], i[3]))\n",
    "\n",
    "#         ### calculate the total number of rcm kmer in each combination of intervals\n",
    "#         ### and store them in num_rcm_kmer_cross_intervals list\n",
    "#         num_rcm_kmer_cross_intervals = []\n",
    "\n",
    "#         for interval_comb in self.interval_combinations:\n",
    "#             upper_interval_pos = interval_comb[0]\n",
    "#             lower_interval_pos = interval_comb[1]\n",
    "#             ## check if the upper in upper_interval_pos and lower in lower_interval_pos\n",
    "#             ## upper or lower + 0.5 * self.seed length was used as the center of rcm kmer\n",
    "\n",
    "#             num_rcm_kmer_cross_intervals.append(sum([(upper + 0.5 * self.seed_len >= upper_interval_pos[0] and\\\n",
    "#                                                       upper + 0.5 * self.seed_len < upper_interval_pos[1]) and\\\n",
    "#                                                      (lower + 0.5 * self.seed_len >= lower_interval_pos[0] and\\\n",
    "#                                                       lower + 0.5 * self.seed_len < lower_interval_pos[1])\\\n",
    "#                                                      for upper, lower in upper_lower_rcm_kmer_pos_pairs]))\n",
    "#         # if sum(num_rcm_kmer_cross_intervals) == 0:\n",
    "#         #     joint_rcm_kmer_dist = np.array(num_rcm_kmer_cross_intervals)\n",
    "#         # else:\n",
    "#         #     joint_rcm_kmer_dist = np.array(num_rcm_kmer_cross_intervals) / sum(num_rcm_kmer_cross_intervals) * 100\n",
    "#         ### return the raw number of rcm in different part of the introns maybe better than the normalized version\n",
    "\n",
    "#         joint_rcm_kmer_dist = list(np.array(num_rcm_kmer_cross_intervals))\n",
    "\n",
    "#         ### normalize the number of rcm_kmer by the total number of comparision tested\n",
    "#         ### This is different for flanking introns and within introns\n",
    "\n",
    "#         # calculate the number of comparison for each allowed seed length: N1 X N2\n",
    "#         # note this is different from the length of the allowed window indices:\n",
    "#         # allowed window indices already filtered by the allowed seed_mismach\n",
    "\n",
    "#         if self.is_flanking_introns:\n",
    "\n",
    "#             num_comparison = (len(input_seq1) - self.seed_len + 1) * (len(input_seq2) - self.seed_len + 1)\n",
    "#         else:\n",
    "#             num_comparison = 1 / 2 * (len(input_seq1) - self.seed_len + 1) * (len(input_seq2) - self.seed_len)\n",
    "\n",
    "# #         ## get the number of rcm_kmers per 10000 comparison\n",
    "\n",
    "#         num_rcm_kmers = len(valid_subseq_pairs_list)\n",
    "#         num_rcm_kmers_per_10000_comp = (num_rcm_kmers / num_comparison) * 10000\n",
    "        \n",
    "#         return self.key, num_rcm_kmers, num_rcm_kmers_per_10000_comp, joint_rcm_kmer_dist\n",
    "        \n",
    "# #         self.num_rcm_kmers = num_rcm_kmers\n",
    "# #         self.num_rcm_kmers_per_10000_comp = num_rcm_kmers_per_10000_comp\n",
    "# #         self.joint_rcm_kmer_dist = joint_rcm_kmer_dist\n",
    "# #         self.valid_subseq_pairs_list = valid_subseq_pairs_list\n",
    "\n",
    "\n",
    "# #         return num_rcm_kmers, num_rcm_kmers_per_10000_comp, joint_rcm_kmer_dist, valid_subseq_pairs_list\n",
    "# #         return self.key, list(joint_rcm_kmer_dist)\n",
    "\n",
    "# #     def subseq_extension(self):\n",
    "    \n",
    "# #         '''\n",
    "# #             This function is used to extend the subseq pairs in the valid_subseq_pairs_list \n",
    "# #             one base at a time until either run out of seq boundary or exceeds the allowed \n",
    "# #             max_mismatch_score; it will return the extended subseq pairs in all_possible_subseqs_dict\n",
    "# #         '''\n",
    "\n",
    "# #         # invoke the self.subseq_validity_check and used the return value\n",
    "        \n",
    "# #         self.subseq_validity_check()\n",
    "        \n",
    "# #         ### inwardly extend the candidate subseq_pairs\n",
    "\n",
    "# #         all_possible_subseqs_dict = {}\n",
    "        \n",
    "# #         complement_dict = {'A':'T', 'G':'C', 'T':'A', 'C':'G', 'N': 'N'}\n",
    "        \n",
    "        \n",
    "# #         ### check to see if dealing with one introns or flanking introns\n",
    "# #         if self.is_flanking_introns:\n",
    "# #             input_seq1 = self.input_seq1\n",
    "# #             input_seq2 = self.input_seq2\n",
    "# #         else:\n",
    "# #             input_seq1 = self.input_seq1\n",
    "# #             input_seq2 = self.input_seq1\n",
    "            \n",
    "# #         ### define the self.allowed_max_mismatch based one the square root of the shortest one of the flanking introns X 2\n",
    "# #         if self.allowed_max_mismatch is None:\n",
    "# #             self.allowed_max_mismatch = np.sqrt(min(len(input_seq1), len(input_seq2))) * 2\n",
    "            \n",
    "# #         for pair_index, valid_subseq_pair in enumerate(self.valid_subseq_pairs_list):\n",
    "\n",
    "# #             # expand the elements in the valid_subseq_pair\n",
    "# #             first_subseq, first_index, second_subseq, second_index, mismatch_score = valid_subseq_pair\n",
    "\n",
    "# #             # initial end index of the first subseq \n",
    "# #             first_down_index = first_index + self.seed_len -1\n",
    "\n",
    "# #             # initial start index of the second subseq \n",
    "# #             second_up_index = second_index\n",
    "            \n",
    "# #             # the extended_sub_seq_pairs collect all the extended subsequences \n",
    "# #             # that are within the max_mismatch_score\n",
    "# #             extended_sub_seq_pairs = []\n",
    "\n",
    "# #             # append the subseqs, their current start_index, end_index, and mismatch_score\n",
    "# #             # remember the python list slicing: end is excluded\n",
    "# #             extended_sub_seq_pairs.append((first_subseq, first_index, first_down_index + 1,\n",
    "# #                                            second_subseq, second_up_index, second_index + self.seed_len,\n",
    "# #                                            mismatch_score))\n",
    "\n",
    "# #             # two different checking criteria for either flanking introns or internal intron\n",
    "# #             # check to make sure the indexs are within the boundary for the flanking intron case\n",
    "            \n",
    "# #             if self.is_flanking_introns:\n",
    "\n",
    "# #                 # inward extension\n",
    "# #                 first_down_index += 1\n",
    "# #                 second_up_index -= 1\n",
    "\n",
    "# #                 while (first_down_index <= len(input_seq1) - 1) and (second_up_index >= 0):\n",
    "\n",
    "# #                     first_down_base = input_seq1[first_down_index]\n",
    "# #                     second_up_base = input_seq2[second_up_index]\n",
    "\n",
    "# #                     # if the next pair of base completely match\n",
    "# #                     if first_down_base == complement_dict[second_up_base]:\n",
    "# #                         first_subseq = first_subseq + first_down_base\n",
    "# #                         second_subseq = second_up_base + second_subseq\n",
    "\n",
    "# #                         extended_sub_seq_pairs.append((first_subseq, first_index,\n",
    "# #                                                        first_down_index + 1, second_subseq,\n",
    "# #                                                        second_up_index, second_index + self.seed_len,\n",
    "# #                                                        mismatch_score))\n",
    "# #                         first_down_index += 1\n",
    "# #                         second_up_index -= 1\n",
    "                        \n",
    "# #                     else:\n",
    "# #                         mismatch_score += 2\n",
    "# #                         if mismatch_score <= self.allowed_max_mismatch: \n",
    "# #                             first_subseq = first_subseq + first_down_base\n",
    "# #                             second_subseq = second_up_base + second_subseq\n",
    "                            \n",
    "# #                             first_down_index += 1\n",
    "# #                             second_up_index -= 1\n",
    "                            \n",
    "# #                         else:\n",
    "# #                             break\n",
    "# #                 ### append the latest subseq pairs to the all_possible_subseqs_dict\n",
    "# #                 all_possible_subseqs_dict[pair_index] = extended_sub_seq_pairs[-1]\n",
    "\n",
    "# #                 ## for the itnernal intron, make sure the extension won't overpass the other subseq\n",
    "# #             else:\n",
    "# #                 # inward extension\n",
    "# #                 first_down_index += 1\n",
    "# #                 second_up_index -= 1\n",
    "                \n",
    "# #                 while (second_up_index - first_down_index) > 2: # maybe >= 2\n",
    "\n",
    "# #                     first_down_base = input_seq1[first_down_index]\n",
    "# #                     second_up_base = input_seq2[second_up_index]\n",
    "\n",
    "# #                     # if the next pair of base completely match\n",
    "# #                     if self.base_conversion(first_down_base) + self.base_conversion(second_up_base) == 0:\n",
    "# #                         first_subseq = first_subseq + first_down_base\n",
    "# #                         second_subseq = second_up_base + second_subseq\n",
    "# #                         extended_sub_seq_pairs.append((first_subseq, first_index,\n",
    "# #                                                        first_down_index + 1, second_subseq,\n",
    "# #                                                        second_up_index, second_index + self.seed_len,\n",
    "# #                                                        mismatch_score))\n",
    "                        \n",
    "# #                         first_down_index += 1\n",
    "# #                         second_up_index -= 1\n",
    "# #                     else:\n",
    "# #                         mismatch_score += 2\n",
    "# #                         if mismatch_score <= self.allowed_max_mismatch: \n",
    "# #                             first_subseq = first_subseq + first_down_base\n",
    "# #                             second_subseq = second_up_base + second_subseq\n",
    "                            \n",
    "# #                             first_down_index += 1\n",
    "# #                             second_up_index -= 1\n",
    "                            \n",
    "# #                         else:\n",
    "# #                             break\n",
    "\n",
    "# #                 # collect the latest extended subseqs\n",
    "# #                 all_possible_subseqs_dict[pair_index] = extended_sub_seq_pairs[-1]\n",
    "\n",
    "# #         self.all_possible_subseqs_dict = all_possible_subseqs_dict\n",
    "    \n",
    "    \n",
    "# #     def interval_intersection_check(self, interval_pair_1, interval_pair_2):\n",
    "# #         '''\n",
    "# #             This function is used to check if one of the interval pair is contained in the other\n",
    "# #         '''\n",
    "# #         # example of one comb: ((0, (3, 22), (33932, 33951)), (1, (3, 16), (40174, 40187)))\n",
    "# #         # first 0 is the list index from all_possible_subseqs_dict's pair index\n",
    "# #         # followed by the start, end of the first arm in the first pair\n",
    "# #         # followed by the start, end of the second arm in the first pair\n",
    "# #         # followed by the information of the second pair\n",
    "        \n",
    "# #         # check if the first pair contains the second pair\n",
    "\n",
    "# #         # first arm comparison\n",
    "# #         first_arm_pair1 = (interval_pair_1[1][0] <= interval_pair_2[1][0]) and (interval_pair_1[1][1] >= interval_pair_2[1][1])\n",
    "        \n",
    "# #         # check if the second pair contains the first pair\n",
    "# #         # first arm comparison\n",
    "# #         first_arm_pair2 = (interval_pair_2[1][0] <= interval_pair_1[1][0]) and (interval_pair_2[1][1] >= interval_pair_1[1][1])\n",
    "\n",
    "\n",
    "# #         # check if the first pair contains the second pair \n",
    "# #         if first_arm_pair1:\n",
    "\n",
    "# #             # second arm comparison\n",
    "# #             second_arm_pair1 = (interval_pair_1[2][0] <= interval_pair_2[2][0]) and (interval_pair_1[2][1] >= interval_pair_2[2][1])\n",
    "\n",
    "# #             if second_arm_pair1:\n",
    "# #                 # return the index for the pair needs to be dropped\n",
    "# #                 return interval_pair_2[0]\n",
    "# #             else:\n",
    "# #                 return -1\n",
    "\n",
    "# #         # check if the second pair contains the first pair\n",
    "# #         elif first_arm_pair2:\n",
    "\n",
    "# #             # second arm comparison\n",
    "# #             second_arm_pair2 = (interval_pair_2[2][0] <= interval_pair_1[2][0]) and (interval_pair_2[2][1] >= interval_pair_1[2][1])\n",
    "\n",
    "# #             if second_arm_pair2:\n",
    "# #                 # return the index for the droped pair\n",
    "# #                 return interval_pair_1[0]\n",
    "# #             else:\n",
    "# #                 return -1\n",
    "\n",
    "# #         else:\n",
    "# #             return -1\n",
    "        \n",
    "        \n",
    "# #     def subseq_consolidation(self):\n",
    "    \n",
    "# #         '''\n",
    "# #             This function takes in the result of the extended subseqs and remove all\n",
    "# #             the redundant subseq pairs with the criteria: if a pair of subseqs completely \n",
    "# #             contained in another pair of subseqs, the contained pair of subseqs will be removed;\n",
    "# #         '''\n",
    "        \n",
    "# #         self.subseq_extension()\n",
    "        \n",
    "# #         interval_pairs = []\n",
    "        \n",
    "# #         for key, value in self.all_possible_subseqs_dict.items():\n",
    "# #             interval_pairs.append((key, value[1:3], value[4:6]))\n",
    "\n",
    "# #         # obtain the all possible pair of combinations of the interval pairs\n",
    "\n",
    "# #         interval_pairs_comb = combinations(interval_pairs, 2)\n",
    "        \n",
    "# #         # example of one comb: ((0, (3, 22), (33932, 33951)), (1, (3, 16), (40174, 40187)))\n",
    "# #         # first 0 is the list index from all_possible_subseqs_dict's pair index\n",
    "# #         # followed by the start, end of the first arm in the first pair\n",
    "# #         # followed by the start, end of the second arm in the first pair\n",
    "# #         # followed by the information of the second pair\n",
    "\n",
    "# #         # check if one interval pair contains the other interval pair\n",
    "# #         dropped_pair_index = set()\n",
    "        \n",
    "# #         for interval_pairs in interval_pairs_comb:\n",
    "# #             dropped_pair_index.add(self.interval_intersection_check(*interval_pairs))\n",
    "\n",
    "# #         # remove the index -1: that are either disjoint or intersected in either arms    \n",
    "# #         if -1 in dropped_pair_index:\n",
    "# #             dropped_pair_index.remove(-1)\n",
    "\n",
    "# #         # drop the redundant keys from the dictionary\n",
    "# #         # put the subseq results in the new dictionary\n",
    "\n",
    "# #         selected_subseqs = {}\n",
    "\n",
    "# #         selected_keys = set(self.all_possible_subseqs_dict.keys()).difference(dropped_pair_index)\n",
    "\n",
    "# #         for key in selected_keys:\n",
    "# #             selected_subseqs[key] = self.all_possible_subseqs_dict[key]\n",
    "            \n",
    "        \n",
    "# #         # process the consolidated subseq dictionary\n",
    "        \n",
    "# #         # store the consolidated seq length\n",
    "# #         consolidated_RCS_len = []\n",
    "        \n",
    "# #         if selected_subseqs:\n",
    "# #             for item in selected_subseqs.values():\n",
    "# #                 consolidated_RCS_len.append(len(item[0]))\n",
    "# #         # assign np.nan to the seed_len that have no corresponding consolidated seqs\n",
    "# #         else:\n",
    "# #             consolidated_RCS_len.append(0)\n",
    "            \n",
    "# #         ## extract the distribution for the extended subseq pair from the selected_subseqs dict\n",
    "        \n",
    "# #         ## get the upper and lower subseq position pairs\n",
    "# #         upper_lower_subseq_pos_pairs = []\n",
    "# #         for subseq_pair in selected_subseqs.values():\n",
    "# #             # subseq_pair[1]: start pos for upper subseq \n",
    "# #             # subseq_pair[4]: start pos for lower subseq\n",
    "# #             # subseq_pair[2]: ending pos for upper subseq\n",
    "# #             subseq_pair_len = int(subseq_pair[2]) - int(subseq_pair[1])\n",
    "# #             upper_lower_subseq_pos_pairs.append((subseq_pair[1], subseq_pair[4], subseq_pair_len))\n",
    "        \n",
    "# #         ### calculate the total number of subseq  in each combination of intervals\n",
    "# #         ### and store them in num_subseq_cross_intervals list\n",
    "        \n",
    "# #         num_subseq_cross_intervals = []\n",
    "        \n",
    "# #         for interval_comb in self.interval_combinations:\n",
    "# #             upper_interval_pos = interval_comb[0]\n",
    "# #             lower_interval_pos = interval_comb[1]\n",
    "# #             ## check if the upper in upper_interval_pos and lower in lower_interval_pos\n",
    "# #             ## upper or lower + 0.5 * subseq_pair_len length was used as the center of subseq pair\n",
    "# #             num_subseq_cross_intervals.append(sum([(upper + 0.5 * subseq_len >= upper_interval_pos[0] and\\\n",
    "# #                                                       upper + 0.5 * subseq_len < upper_interval_pos[1]) and\\\n",
    "# #                                                      (lower + 0.5 * subseq_len >= lower_interval_pos[0] and\\\n",
    "# #                                                       lower + 0.5 * subseq_len < lower_interval_pos[1])\\\n",
    "# #                                                      for upper, lower, subseq_len in upper_lower_subseq_pos_pairs]))\n",
    "            \n",
    "# #         joint_subseq_pair_dist = list(np.array(num_subseq_cross_intervals))\n",
    "# #         self.joint_subseq_pair_dist = joint_subseq_pair_dist\n",
    "            \n",
    "# #         self.rcm_summary_stats = list(np.percentile(consolidated_RCS_len, [0, 25, 50, 75, 100]))\n",
    "\n",
    "# #         return self.key,self.num_rcm_kmers, self.num_rcm_kmers_per_10000_comp, self.joint_rcm_kmer_dist, self.rcm_summary_stats, self.joint_subseq_pair_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a329a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class RCS_finder():\n",
    "    '''\n",
    "        This is a python class that can find the imperfect reverse complementary sequences (RCS) within\n",
    "        a intronic sequence ranging from 50bps to 50kbps; it can also find the imperfect RCS of two\n",
    "        flanking introns each ranging from 50bps to 50kbps.\n",
    "\n",
    "        input_seq1: the Up flanking intron;\n",
    "        input_seq2: the Lower flanking intron;\n",
    "        is_flanking_introns: boolean value indicating whether dealing with two flanking introns\n",
    "        if is_flanking_introns == False, the input_seq2 will be ignored and only input_seq1 will be used;\n",
    "        seed_len: seed length for the initial RCS search\n",
    "        seq_fraction_of_spacer: the minimal portion of the seq length between the two paired seed region\n",
    "                                when dealing with one intron (between 0 to 1); set spacer to 0 if\n",
    "                                spacer length is not used for filtering;\n",
    "        allowed_seed_mismatch: allowed the number of mismatch in the seed region: default is 1 (i.e., 2 score)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, key=None, input_seq1=None, input_seq2=None, is_flanking_introns=None, \n",
    "                 is_upper_intron=None, seq_fraction_of_spacer=None,\n",
    "                 seed_len=None, allowed_seed_mismatch=None):\n",
    "        \n",
    "        ### input_seq1 is the upper intronic sequence\n",
    "        ### input_seq2 is the lower intronic sequence\n",
    "        self.key = key\n",
    "        self.input_seq1 = input_seq1\n",
    "        self.input_seq2 = input_seq2\n",
    "        self.is_flanking_introns = is_flanking_introns\n",
    "        self.is_upper_intron = is_upper_intron\n",
    "        self.seq_fraction_of_spacer = seq_fraction_of_spacer\n",
    "        self.seed_len = seed_len\n",
    "        self.allowed_seed_mismatch = allowed_seed_mismatch\n",
    "#         self.num_rcm_kmers = None\n",
    "#         self.num_rcm_kmers_per_10000_comp = None\n",
    "\n",
    "\n",
    "    def base_conversion(self, seq):\n",
    "        '''\n",
    "            convert the input sequence into the numerical representation\n",
    "        '''\n",
    "        base_mapping = {'A': 1, 'T': -1, 'C': 1j, 'G': -1j, 'N': 0}\n",
    "        if len(seq) >= 2:\n",
    "            seq_map = np.array([base_mapping[i] for i in seq])\n",
    "        else:\n",
    "            seq_map = base_mapping[seq]\n",
    "        return seq_map\n",
    "\n",
    "    def get_sub_seq_score(self, seq):\n",
    "\n",
    "        '''\n",
    "            This function starts with a input sequence and return\n",
    "            the cummulative sum of the subsequence of length min_seq\n",
    "        '''\n",
    "        # get the augumented input sequence\n",
    "        aug_seq = 'N' + seq\n",
    "        # convert the augumented sequence into the numerical representation\n",
    "        aug_seq_M = self.base_conversion(aug_seq)\n",
    "        # get the cumulative sum of the augumented sequence\n",
    "        aug_seq_cum_M = aug_seq_M.cumsum()\n",
    "        # get the cumulative sum of the original input sequence\n",
    "        seq_cum_M = aug_seq_cum_M[1:]\n",
    "        # get subsequence score with length=self.seed_len\n",
    "        sub_seq_score = seq_cum_M[self.seed_len - 1:] - aug_seq_cum_M[:len(aug_seq) - self.seed_len]\n",
    "        return sub_seq_score\n",
    "\n",
    "    def get_allowed_window_index(self):\n",
    "        '''\n",
    "            This function takes in the subseq_scores, and a fraction number (i.e., betwen 0 and 1) and return\n",
    "            the allowed pair of window index that can be used for further subseqs verification\n",
    "        '''\n",
    "        \n",
    "        if self.is_flanking_introns:\n",
    "#             print(self.input_seq1)\n",
    "#             print(self.input_seq2)\n",
    "            # deal with flanking introns\n",
    "            subseq_score1 = self.get_sub_seq_score(self.input_seq1).astype(np.complex64)\n",
    "            subseq_score2 = self.get_sub_seq_score(self.input_seq2).astype(np.complex64)\n",
    "            \n",
    "            # put all possible pair-wise subseq addition score in the matrix\n",
    "            # first subseq as the column, second subseq as the row\n",
    "            subseq_scores_sum = subseq_score1.reshape((-1, 1)) + subseq_score2.reshape((1, -1))\n",
    "            \n",
    "            # get the sum of the absolute value of imaginary part and real part\n",
    "            subseq_scores_abs_sum_mat = abs(subseq_scores_sum.imag) + abs(subseq_scores_sum.real)\n",
    "            \n",
    "            # get the index for the pair of subseqs that potentially have at most 1 mismatch (i.e., abs sum <= 2)\n",
    "            first_window, second_window = np.where(subseq_scores_abs_sum_mat <= self.allowed_seed_mismatch)\n",
    "\n",
    "            return first_window, second_window\n",
    "        \n",
    "        elif self.is_upper_intron:\n",
    "            seq = self.input_seq1\n",
    "        else:\n",
    "            seq = self.input_seq2\n",
    "        \n",
    "#         print(seq)\n",
    "        \n",
    "        # deal with one intron only, use the seq\n",
    "        subseq_scores = self.get_sub_seq_score(seq)\n",
    "\n",
    "        ### this step is fast\n",
    "        subseq_scores = subseq_scores.astype(np.complex64)\n",
    "\n",
    "        #### this step takes about 7 seconds\n",
    "        # put all possible pair-wise subseq addition score in the matrix\n",
    "        subseq_scores_sum = subseq_scores.reshape((-1, 1)) + subseq_scores.reshape((1, -1))\n",
    "\n",
    "        #### this step takes about 11 seconds\n",
    "        # get the sum of the absolute value of imaginary part and real part\n",
    "        subseq_scores_abs_sum_mat = abs(subseq_scores_sum.imag) + abs(subseq_scores_sum.real)\n",
    "\n",
    "        #### this step takes about 9 seconds\n",
    "        # obtain the lower triangular index including the diagnoal\n",
    "        tril_index = np.tril_indices(subseq_scores_abs_sum_mat.shape[0])\n",
    "\n",
    "        #### this step takes about 7 seconds\n",
    "        # change the lower triangular value to be bigger than 2, thus don't need to filter due to the  matrix symetry\n",
    "        subseq_scores_abs_sum_mat[tril_index] = self.allowed_seed_mismatch + 1\n",
    "\n",
    "        #### this step takes about 9 seconds\n",
    "        # get the index for the pair of subseqs that potentially have at most 1 mismatch (i.e., abs sum <= 2)\n",
    "        first_window, second_window = np.where(subseq_scores_abs_sum_mat <= self.allowed_seed_mismatch)\n",
    "        \n",
    "         ### this step takes about 0.9 seconds\n",
    "        # get the window distance for each pair of subseqs\n",
    "        window_num_diff = second_window - first_window\n",
    "\n",
    "        #### this step takes about 0.7 seconds\n",
    "        # get the base pair distance for each pair of subseqs # 10 is the default arm length\n",
    "        spacer = window_num_diff - self.seed_len\n",
    "\n",
    "        ### this step takes about 0.3 seconds; set fraction_of_spacer at least to 0 to\n",
    "        ### avoid the overlapping windows\n",
    "        # base pair distance for each pair of subseqs at least half the total seq length\n",
    "        allowed_index = (spacer >= len(seq) * self.seq_fraction_of_spacer)\n",
    "\n",
    "        ### these two steps take about 0.6 seconds\n",
    "        # get the allowed window index\n",
    "        allowed_first_window = first_window[allowed_index]\n",
    "        allowed_second_window = second_window[allowed_index]\n",
    "\n",
    "        return allowed_first_window, allowed_second_window\n",
    "\n",
    "\n",
    "    def subseq_validity_check(self):\n",
    "        '''\n",
    "            This function is used to check wether the subseq pairs identified in get_allowed_window_index function\n",
    "            is valid or not by calling the check_valid_subseq_pairs function,\n",
    "            This function also return the relative location of the valid rcm kmers as well as number of\n",
    "            kmers per 10000 comparison\n",
    "        '''\n",
    "        first_window, second_window = self.get_allowed_window_index()\n",
    "\n",
    "        valid_subseq_pairs_list = []\n",
    "\n",
    "        complement_dict = {'A': 'T', 'G': 'C', 'T': 'A', 'C': 'G', 'N': 'N'}\n",
    "\n",
    "        ### check to see if dealing with one introns or flanking introns\n",
    "        if self.is_flanking_introns:\n",
    "            input_seq1 = self.input_seq1\n",
    "            input_seq2 = self.input_seq2\n",
    "            \n",
    "        elif self.is_upper_intron:\n",
    "            input_seq1 = self.input_seq1\n",
    "            input_seq2 = self.input_seq1\n",
    "        else:\n",
    "            input_seq1 = self.input_seq2\n",
    "            input_seq2 = self.input_seq2\n",
    "\n",
    "        for first_index, second_index in zip(first_window, second_window):\n",
    "\n",
    "            # set it for each window pair\n",
    "            seed_mismatch_score = 0\n",
    "\n",
    "            first_subseq, second_subseq = input_seq1[first_index:self.seed_len + first_index], \\\n",
    "                                          input_seq2[second_index:self.seed_len + second_index]\n",
    "\n",
    "            # check for the two ends first to make sure end is matching\n",
    "            if first_subseq[0] == complement_dict[second_subseq[-1]]:\n",
    "                # check the interior subseq\n",
    "                for i in range(1, self.seed_len):\n",
    "                    if first_subseq[i] != complement_dict[second_subseq[-i - 1]]:\n",
    "                        seed_mismatch_score += 2\n",
    "                        # if total mismatch already bigger than 2 abort the further checking\n",
    "                        if seed_mismatch_score > self.allowed_seed_mismatch:\n",
    "                            break\n",
    "\n",
    "                if seed_mismatch_score <= self.allowed_seed_mismatch:\n",
    "                    valid_subseq_pairs_list.append((first_subseq, first_index, second_subseq, \\\n",
    "                                                    second_index, seed_mismatch_score))\n",
    "                    \n",
    "#         print(valid_subseq_pairs_list)  \n",
    "                ### The following code: extract the rcm kmer location distribution relative\n",
    "        ### to the corresponding upper or lower intron\n",
    "\n",
    "        ### create interval list for upper and lower introns based on the upper and lower intron length\n",
    "\n",
    "        upper_equal_space_list = np.linspace(start=0, stop=len(input_seq1), num=5+1)\n",
    "\n",
    "        lower_equal_space_list = np.linspace(start=0, stop=len(input_seq2), num=5+1)\n",
    "\n",
    "        upper_interval_list = []\n",
    "        lower_interval_list = []\n",
    "\n",
    "        for i in range(len(upper_equal_space_list) - 1):\n",
    "            upper_interval = (upper_equal_space_list[i], upper_equal_space_list[i + 1])\n",
    "            upper_interval_list.append(upper_interval)\n",
    "\n",
    "        for i in range(len(lower_equal_space_list) - 1):\n",
    "            lower_interval = (lower_equal_space_list[i], lower_equal_space_list[i + 1])\n",
    "            lower_interval_list.append(lower_interval)\n",
    "\n",
    "        ### get the combination of interval from upper and lower introns 5 x 5 interval in this case\n",
    "        ### if num = 6\n",
    "        interval_combinations = list(product(upper_interval_list, lower_interval_list))\n",
    "        \n",
    "        ## save this interval_combinations to self.interval_combinations for the distribution of extended subseq pairs\n",
    "        self.interval_combinations = interval_combinations\n",
    "        \n",
    "\n",
    "        ### get the upper and lower rcm kmer position pairs\n",
    "        upper_lower_rcm_kmer_pos_pairs = []\n",
    "        for i in valid_subseq_pairs_list:\n",
    "            upper_lower_rcm_kmer_pos_pairs.append((i[1], i[3]))\n",
    "\n",
    "        ### calculate the total number of rcm kmer in each combination of intervals\n",
    "        ### and store them in num_rcm_kmer_cross_intervals list\n",
    "        num_rcm_kmer_cross_intervals = []\n",
    "\n",
    "        for interval_comb in self.interval_combinations:\n",
    "            upper_interval_pos = interval_comb[0]\n",
    "            lower_interval_pos = interval_comb[1]\n",
    "            ## check if the upper in upper_interval_pos and lower in lower_interval_pos\n",
    "            ## upper or lower + 0.5 * self.seed length was used as the center of rcm kmer\n",
    "\n",
    "            num_rcm_kmer_cross_intervals.append(sum([(upper + 0.5 * self.seed_len >= upper_interval_pos[0] and\\\n",
    "                                                      upper + 0.5 * self.seed_len < upper_interval_pos[1]) and\\\n",
    "                                                     (lower + 0.5 * self.seed_len >= lower_interval_pos[0] and\\\n",
    "                                                      lower + 0.5 * self.seed_len < lower_interval_pos[1])\\\n",
    "                                                     for upper, lower in upper_lower_rcm_kmer_pos_pairs]))\n",
    "        # if sum(num_rcm_kmer_cross_intervals) == 0:\n",
    "        #     joint_rcm_kmer_dist = np.array(num_rcm_kmer_cross_intervals)\n",
    "        # else:\n",
    "        #     joint_rcm_kmer_dist = np.array(num_rcm_kmer_cross_intervals) / sum(num_rcm_kmer_cross_intervals) * 100\n",
    "        ### return the raw number of rcm in different part of the introns maybe better than the normalized version\n",
    "\n",
    "        joint_rcm_kmer_dist = np.array(num_rcm_kmer_cross_intervals)\n",
    "\n",
    "                    \n",
    "#         self.valid_subseq_pairs_list = valid_subseq_pairs_list\n",
    "        \n",
    "#         print(self.valid_subseq_pairs_list)\n",
    "        \n",
    "#         self.num_rcm_kmers = len(valid_subseq_pairs_list)\n",
    "        \n",
    "        \n",
    "#         if self.is_flanking_introns:\n",
    "\n",
    "#             num_comparison = (len(input_seq1) - self.seed_len + 1) * (len(input_seq2) - self.seed_len + 1)\n",
    "#         else:\n",
    "#             num_comparison = 1 / 2 * (len(input_seq1) - self.seed_len + 1) * (len(input_seq2) - self.seed_len)\n",
    "\n",
    "#         ## get the number of rcm_kmers distrubution per 10000 comparison\n",
    "\n",
    "#         joint_rcm_kmer_dist_per_million = (joint_rcm_kmer_dist / num_comparison) * 1000000\n",
    "\n",
    "        return self.key, list(joint_rcm_kmer_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e808d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq1 = BS_LS_flanking_seq_dict[all_keys_sorted_flanking_introns[0]]['U_flanking_seq']\n",
    "# seq2 = BS_LS_flanking_seq_dict[all_keys_sorted_flanking_introns[0]]['L_flanking_seq']\n",
    "\n",
    "# rcs_test = RCS_finder(key=all_keys_sorted_flanking_introns[0], input_seq1=seq1, input_seq2=seq2, is_flanking_introns=True,\n",
    "#                                               seed_len=20,is_upper_intron=False,\n",
    "#                                               allowed_seed_mismatch=0,\n",
    "#                                               seq_fraction_of_spacer=0)\n",
    "\n",
    "# rcs_test.subseq_validity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2aeba13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  52,   0,   0, 447,   0, 104,  15])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ 1, 52, 0, 0, 447, 0, 104, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b474ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcs_flanking_introns_ray_chunk(seq_list, seed_len):\n",
    "    rcs_list = []\n",
    "    for key, value in seq_list:\n",
    "        seq1 = value['U_flanking_seq']\n",
    "#         print(len(seq1))\n",
    "        seq2 = value['L_flanking_seq']\n",
    "#         print(len(seq2))\n",
    "        rcs_list.append(RCS_finder.remote(key=key, input_seq1=seq1, input_seq2=seq2, \n",
    "                                              is_flanking_introns=True,\n",
    "                                              seed_len=seed_len, is_upper_intron=False, \n",
    "                                              seq_fraction_of_spacer=0,\n",
    "                                              allowed_seed_mismatch=0))\n",
    "\n",
    "    results = ray.get([rcs.subseq_validity_check.remote() for rcs in rcs_list])\n",
    "    return results\n",
    "\n",
    "\n",
    "def loop_flanking_introns_ray_chunk(BS_LS_flanking_seq_dict, chunk_keys, rcm_dump_folder, seed_len, flanking_len):\n",
    "    '''\n",
    "        This function loops chunk_keys and call the rcs_flanking_introns_ray_chunk function\n",
    "        in each loop and collect the results in a dict and dump them in rcm_dump_folder\n",
    "    '''\n",
    "    rcs_flanking_introns_results = []\n",
    "    result_dict = defaultdict(list)\n",
    "\n",
    "    for i in range(len(chunk_keys)):\n",
    "\n",
    "        seq_key = chunk_keys[i]\n",
    "\n",
    "        seq_list = [(key, BS_LS_flanking_seq_dict[key]) for key in seq_key]\n",
    "\n",
    "        result = rcs_flanking_introns_ray_chunk(seq_list=seq_list, seed_len=seed_len)\n",
    "\n",
    "        rcs_flanking_introns_results.append(result)\n",
    "\n",
    "#         print(rcs_flanking_introns_results)\n",
    "\n",
    "        \n",
    "    flat_list = [item for chunk in rcs_flanking_introns_results for item in chunk]\n",
    "\n",
    "    for item in flat_list:\n",
    "        rcm_num = [float(i) for i in item[1]]\n",
    "        result_dict[item[0]].append(rcm_num)\n",
    "        \n",
    "#         rcm_num_norm = [float(i) for i in item[2]]\n",
    "#         result_dict[item[0]].append(rcm_num_norm)\n",
    "        \n",
    "        \n",
    "    file_name = f\"to_{i + 1}_rcm_flanking_{flanking_len}_bps_introns_{seed_len}mer.json\"\n",
    "\n",
    "    with open(os.path.join(rcm_dump_folder, file_name), 'w') as f:\n",
    "        json.dump(result_dict, f)\n",
    "\n",
    "    print(f'flanking_rcm {i + 1} finished')\n",
    "\n",
    "    ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa323eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f1dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcs_upper_introns_ray_chunk(seq_list, seed_len):\n",
    "    rcs_list = []\n",
    "    for key, value in seq_list:\n",
    "        seq1 = value['U_flanking_seq']\n",
    "        seq2 = value['L_flanking_seq']\n",
    "        rcs_list.append(RCS_finder.remote(key=key, input_seq1=seq1, input_seq2=seq2, \n",
    "                                              is_flanking_introns=False,\n",
    "                                              seed_len=seed_len, is_upper_intron=True,\n",
    "                                              seq_fraction_of_spacer=0,\n",
    "                                              allowed_seed_mismatch=0))\n",
    "\n",
    "    results = ray.get([rcs.subseq_validity_check.remote() for rcs in rcs_list])\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def loop_upper_introns_ray_chunk(BS_LS_flanking_seq_dict, chunk_keys, rcm_dump_folder, seed_len, flanking_len):\n",
    "    '''\n",
    "        This function loops chunk_keys and call the rcs_upper_introns_ray_chunk function\n",
    "        in each loop and collect the results in a list\n",
    "    '''\n",
    "    rcs_upper_introns_results = []\n",
    "    result_dict = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    for i in range(len(chunk_keys)):\n",
    "\n",
    "        seq_key = chunk_keys[i]\n",
    "\n",
    "        seq_list = [(key, BS_LS_flanking_seq_dict[key]) for key in seq_key]\n",
    "\n",
    "        result = rcs_upper_introns_ray_chunk(seq_list=seq_list, seed_len=seed_len)\n",
    "\n",
    "        rcs_upper_introns_results.append(result)\n",
    "\n",
    "#         print(rcs_upper_introns_results)\n",
    "\n",
    "        \n",
    "    flat_list = [item for chunk in rcs_upper_introns_results for item in chunk]\n",
    "\n",
    "    for item in flat_list:\n",
    "        rcm_num = [float(i) for i in item[1]]\n",
    "        result_dict[item[0]].append(rcm_num)\n",
    "\n",
    "    file_name = f\"to_{i + 1}_rcm_upper_{flanking_len}_bps_introns_{seed_len}mer.json\"\n",
    "\n",
    "    with open(os.path.join(rcm_dump_folder, file_name), 'w') as f:\n",
    "        json.dump(result_dict, f)\n",
    "\n",
    "    print(f'upper_rcm {i + 1} finished')\n",
    "\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1fc42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcs_lower_introns_ray_chunk(seq_list, seed_len):\n",
    "    rcs_list = []\n",
    "    for key, value in seq_list:\n",
    "        seq1 = value['U_flanking_seq']\n",
    "        seq2 = value['L_flanking_seq']\n",
    "        rcs_list.append(RCS_finder.remote(key=key, input_seq1=seq1, input_seq2=seq2, \n",
    "                                              is_flanking_introns=False,\n",
    "                                              seed_len=seed_len, is_upper_intron=False,\n",
    "                                              seq_fraction_of_spacer=0,\n",
    "                                              allowed_seed_mismatch=0))\n",
    "\n",
    "    results = ray.get([rcs.subseq_validity_check.remote() for rcs in rcs_list])\n",
    "    return results\n",
    "\n",
    "\n",
    "def loop_lower_introns_ray_chunk(BS_LS_flanking_seq_dict, chunk_keys, rcm_dump_folder, seed_len, flanking_len):\n",
    "    '''\n",
    "        This function loops chunk_keys and call the rcs_lower_introns_ray_chunk function\n",
    "        in each loop and collect the results in a list\n",
    "    '''\n",
    "    rcs_lower_introns_results = []\n",
    "    result_dict = defaultdict(list)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(len(chunk_keys)):\n",
    "\n",
    "        seq_key = chunk_keys[i]\n",
    "\n",
    "        seq_list = [(key, BS_LS_flanking_seq_dict[key]) for key in seq_key]\n",
    "\n",
    "        result = rcs_lower_introns_ray_chunk(seq_list=seq_list, seed_len=seed_len)\n",
    "\n",
    "        rcs_lower_introns_results.append(result)\n",
    "#         print(rcs_lower_introns_results)\n",
    "\n",
    "\n",
    "    flat_list = [item for chunk in rcs_lower_introns_results for item in chunk]\n",
    "    \n",
    "    \n",
    "    for item in flat_list:\n",
    "        \n",
    "        rcm_num = [float(i) for i in item[1]]\n",
    "        result_dict[item[0]].append(rcm_num)\n",
    "        \n",
    "#         rcm_num_norm = [float(i) for i in item[2]]\n",
    "#         result_dict[item[0]].append(rcm_num_norm)\n",
    "\n",
    "    file_name = f\"to_{i + 1}_rcm_lower_{flanking_len}_bps_introns_{seed_len}mer.json\"\n",
    "    with open(os.path.join(rcm_dump_folder, file_name), 'w') as f:\n",
    "        json.dump(result_dict, f)\n",
    "\n",
    "    print(f'lower_rcm {i + 1} finished')\n",
    "\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1fe5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff855eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcm_folder = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/flanking_dicts/rcm_scores/'\n",
    "\n",
    "BS_LS_flanking_seq_dict_list = []\n",
    "\n",
    "for flanking_intron_len in [200, 300, 400, 2500]:\n",
    "    \n",
    "    with open(f'/home/wangc90/circRNA/circRNA_Data/BS_LS_data/flanking_dicts/BS_LS_intronic_flanking_seq_{flanking_intron_len}_bps.json') as f:\n",
    "        BS_LS_flanking_seq_dict = json.load(f)\n",
    "        BS_LS_flanking_seq_dict_list.append(BS_LS_flanking_seq_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb6ed4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 300, 400, 2500]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i['chr21|40792631|40807499|-']['L_flanking_seq']) for i in BS_LS_flanking_seq_dict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23d3d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = [key for key in BS_LS_flanking_seq_dict_list[0].keys()]\n",
    "\n",
    "chunk_keys_flanking_introns = []\n",
    "for i in range(0, len(all_keys), 50):\n",
    "    chunk_keys_flanking_introns.append(all_keys[i:i+50])\n",
    "    \n",
    "chunk_keys_within_introns = []\n",
    "for i in range(0, len(all_keys), 50):\n",
    "    chunk_keys_within_introns.append(all_keys[i:i+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d21da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get flanking rcm feature for 200 bps intron with seed length 5\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 200 bps intron with seed length 5\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 200 bps intron with seed length 5\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 200 bps intron with seed length 7\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 200 bps intron with seed length 7\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 200 bps intron with seed length 7\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 200 bps intron with seed length 9\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 200 bps intron with seed length 9\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 200 bps intron with seed length 9\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 200 bps intron with seed length 11\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 200 bps intron with seed length 11\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 200 bps intron with seed length 11\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 200 bps intron with seed length 13\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 200 bps intron with seed length 13\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 200 bps intron with seed length 13\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 300 bps intron with seed length 5\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 300 bps intron with seed length 5\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 300 bps intron with seed length 5\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 300 bps intron with seed length 7\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 300 bps intron with seed length 7\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 300 bps intron with seed length 7\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 300 bps intron with seed length 9\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 300 bps intron with seed length 9\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 300 bps intron with seed length 9\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 300 bps intron with seed length 11\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 300 bps intron with seed length 11\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 300 bps intron with seed length 11\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 300 bps intron with seed length 13\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 300 bps intron with seed length 13\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 300 bps intron with seed length 13\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 400 bps intron with seed length 5\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 400 bps intron with seed length 5\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 400 bps intron with seed length 5\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 400 bps intron with seed length 7\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 400 bps intron with seed length 7\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 400 bps intron with seed length 7\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 400 bps intron with seed length 9\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 400 bps intron with seed length 9\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 400 bps intron with seed length 9\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 400 bps intron with seed length 11\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 400 bps intron with seed length 11\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 400 bps intron with seed length 11\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 400 bps intron with seed length 13\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 400 bps intron with seed length 13\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 400 bps intron with seed length 13\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 2500 bps intron with seed length 5\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 2500 bps intron with seed length 5\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 2500 bps intron with seed length 5\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 2500 bps intron with seed length 7\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 2500 bps intron with seed length 7\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 2500 bps intron with seed length 7\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 2500 bps intron with seed length 9\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 2500 bps intron with seed length 9\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 2500 bps intron with seed length 9\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 2500 bps intron with seed length 11\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 2500 bps intron with seed length 11\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 2500 bps intron with seed length 11\n",
      "lower_rcm 485 finished\n",
      "get flanking rcm feature for 2500 bps intron with seed length 13\n",
      "flanking_rcm 485 finished\n",
      "get upper rcm feature for 2500 bps intron with seed length 13\n",
      "upper_rcm 485 finished\n",
      "get lower rcm feature for 2500 bps intron with seed length 13\n",
      "lower_rcm 485 finished\n"
     ]
    }
   ],
   "source": [
    "seed_len_list = [5, 7, 9, 11, 13]\n",
    "flanking_len_list = [200, 300, 400, 2500]\n",
    "\n",
    "for index, value in enumerate(BS_LS_flanking_seq_dict_list):\n",
    "    \n",
    "    for seed_len in seed_len_list:\n",
    "        print(f'get flanking rcm feature for {flanking_len_list[index]} bps intron with seed length {seed_len}')\n",
    "\n",
    "        loop_flanking_introns_ray_chunk(BS_LS_flanking_seq_dict=value, chunk_keys=chunk_keys_flanking_introns,\n",
    "                                        rcm_dump_folder=rcm_folder, seed_len=seed_len,\n",
    "                                       flanking_len=flanking_len_list[index])\n",
    "        # get rcm feature for upper introns:\n",
    "        print(f'get upper rcm feature for {flanking_len_list[index]} bps intron with seed length {seed_len}')\n",
    "\n",
    "        loop_upper_introns_ray_chunk(BS_LS_flanking_seq_dict=value, chunk_keys=chunk_keys_within_introns,\n",
    "                                     rcm_dump_folder=rcm_folder, seed_len=seed_len,\n",
    "                                     flanking_len=flanking_len_list[index])\n",
    "    # #     ### get rcm feature for lower introns:\n",
    "        print(f'get lower rcm feature for {flanking_len_list[index]} bps intron with seed length {seed_len}')\n",
    "\n",
    "        loop_lower_introns_ray_chunk(BS_LS_flanking_seq_dict=value, chunk_keys=chunk_keys_within_introns,\n",
    "                                     rcm_dump_folder=rcm_folder, seed_len=seed_len,\n",
    "                                     flanking_len=flanking_len_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c3556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
