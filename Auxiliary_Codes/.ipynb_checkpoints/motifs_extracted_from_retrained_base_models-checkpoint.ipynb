{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65958399",
   "metadata": {},
   "source": [
    "### get the consensus motifs from retrained Base_model1_10000, 9000 and 8000; get the consensus motifs from Base_model2_10000, 9000 and 8000 and compare the consensus motifs from the two model structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a189fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f68d8248bf0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "# from torchmetrics.classification import F1Score\n",
    "import pickle\n",
    "import sys\n",
    "### import Dataset prepartion and model training classes from Auxiliary_Codes folder\n",
    "from BS_LS_DataSet import BS_LS_DataSet_Prep, BS_LS_upper_lower_rcm\n",
    "from PPM_extraction import PPM_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f424f",
   "metadata": {},
   "source": [
    "### extract motifs for 10000 training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2748b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr5|138837130|138837392|- has N in the extracted junctions, belongs to BS\n",
      "There are 0 overlapped flanking sequence from BS and LS  \n",
      "There are 7 repeated BS sequences\n",
      "There are 2 repeated LS sequences\n"
     ]
    }
   ],
   "source": [
    "BS_LS_coordinates_path = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/updated_data/BS_LS_coordinates_final.csv'\n",
    "hg19_seq_dict_json_path = '/home/wangc90/circRNA/circRNA_Data/hg19_seq/hg19_seq_dict.json'\n",
    "flanking_dict_folder = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/flanking_dicts/'\n",
    "bs_ls_dataset = BS_LS_DataSet_Prep(BS_LS_coordinates_path=BS_LS_coordinates_path,\n",
    "                                   hg19_seq_dict_json_path=hg19_seq_dict_json_path,\n",
    "                                   flanking_dict_folder=flanking_dict_folder,\n",
    "                                   flanking_junction_bps=100,\n",
    "                                   flanking_intron_bps=100,\n",
    "                                   training_size=10000)\n",
    "\n",
    "\n",
    "bs_ls_dataset.get_junction_flanking_intron_seq()\n",
    "\n",
    "### use the 10000 for training RCM and junction seq and use 1000 for combine them\n",
    "train_key1, _, test_keys = bs_ls_dataset.get_train_test_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2eae971e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_key1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d175f",
   "metadata": {},
   "source": [
    "### The corresponding retrained_model structure has to be loaded for the motif extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7dcf77",
   "metadata": {},
   "source": [
    "### Base_model2_10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8aa20e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 2 input sequence 4 X 200 + 4 X 200 with 1 or 2CNN layer\n",
    "class Model2_optuna_upper_10000(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the upper half of the sequence with 1 or 2 CNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "        super(Model2_optuna_upper_10000, self).__init__()\n",
    "        # convlayer 1\n",
    "#         self.out_channel1 = trial.suggest_categorical('upper_out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 512\n",
    "#         kernel_size1 = trial.suggest_categorical('upper_kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 15\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('upper_maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 200 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('upper_out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('upper_kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                               kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('upper_maxpool2', [5, 10])\n",
    "        self.maxpool2 = 10\n",
    "        self.conv2_out_dim = 200 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Model2_optuna_lower_10000(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the upper half of the sequence with 1 or 2 CNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(Model2_optuna_lower_10000, self).__init__()\n",
    "        # convlayer 1\n",
    "#         self.out_channel1 = trial.suggest_categorical('lower_out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 256\n",
    "#         kernel_size1 = trial.suggest_categorical('lower_kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 13\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('lower_maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 200 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('lower_out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('lower_kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                               kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('lower_maxpool2', [5, 10])\n",
    "        self.maxpool2 = 10\n",
    "        self.conv2_out_dim = 200 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ConcatModel2_optuna_10000(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(ConcatModel2_optuna_10000, self).__init__()\n",
    "        ### cnn for the upper half sequence\n",
    "        self.cnn_upper = Model2_optuna_upper_10000(trial)\n",
    "\n",
    "        # this is for two convlayer\n",
    "        self.upper_out_dim = self.cnn_upper.conv2_out_dim\n",
    "        self.upper_out_channel = self.cnn_upper.out_channel2\n",
    "\n",
    "        ### cnn for the lower half sequence\n",
    "        self.cnn_lower = Model2_optuna_lower_10000(trial)\n",
    "\n",
    "            # this is for two convlayer\n",
    "        self.lower_out_dim = self.cnn_lower.conv2_out_dim\n",
    "        self.lower_out_channel = self.cnn_lower.out_channel2\n",
    "\n",
    "        self.upper_lower_concate_fc1_in = self.upper_out_channel * self.upper_out_dim + \\\n",
    "                                 self.lower_out_channel * self.lower_out_dim\n",
    "\n",
    "#         self.upper_lower_concate_fc1_out = trial.suggest_categorical('concat_fc1_out', [128, 256, 512])\n",
    "        self.upper_lower_concate_fc1_out = 512\n",
    "\n",
    "        self.upper_lower_concate_fc1 = nn.Linear(self.upper_lower_concate_fc1_in, self.upper_lower_concate_fc1_out)\n",
    "\n",
    "        self.upper_lower_concate_fc1_bn = nn.BatchNorm1d(self.upper_lower_concate_fc1_out)\n",
    "\n",
    "#         dropout_rate_fc1 = trial.suggest_categorical(\"concat_dropout_rate_fc1\",  [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc1 = 0\n",
    "        self.drop_nn1 = nn.Dropout(p=dropout_rate_fc1)\n",
    "\n",
    "        # fc layer2\n",
    "        # use dimension output with nn.CrossEntropyLoss()\n",
    "#         self.upper_lower_concate_fc2_out = trial.suggest_categorical('concat_fc2_out', [4, 8, 16, 32])\n",
    "        self.upper_lower_concate_fc2_out = 4\n",
    "        self.upper_lower_concate_fc2 = nn.Linear(self.upper_lower_concate_fc1_out, self.upper_lower_concate_fc2_out)\n",
    "        self.upper_lower_concate_fc2_bn = nn.BatchNorm1d(self.upper_lower_concate_fc2_out)\n",
    "\n",
    "#         dropout_rate_fc2 = trial.suggest_categorical(\"concat_dropout_rate_fc2\", [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc2 = 0\n",
    "        self.drop_nn2 = nn.Dropout(p=dropout_rate_fc2)\n",
    "\n",
    "        self.upper_lower_concate_final = nn.Linear(self.upper_lower_concate_fc2_out, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, seq_upper_feature, seq_lower_feature):\n",
    "\n",
    "        # obatin the result from the cnn upper\n",
    "        x1 = self.cnn_upper(seq_upper_feature)\n",
    "\n",
    "        # obtain the result from the cnn lower\n",
    "        x2 = self.cnn_lower(seq_lower_feature)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "\n",
    "        # feed the concatenated feature to fc1\n",
    "        out = self.upper_lower_concate_fc1(x)\n",
    "        out = self.drop_nn1(torch.relu(self.upper_lower_concate_fc1_bn(out)))\n",
    "\n",
    "        out = self.upper_lower_concate_fc2(out)\n",
    "        out = self.drop_nn2(torch.relu(self.upper_lower_concate_fc2_bn(out)))\n",
    "\n",
    "        out = self.upper_lower_concate_final(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885f43a",
   "metadata": {},
   "source": [
    "Base_model2_10000: upper: self.out_channel1 = 512; kernel_size1 = 15; padding=(kernel_size1 - 1) // 2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "055e45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254\n",
    "### https://github.com/uci-cbcl/DanQ/issues/9\n",
    "\n",
    "### upper kernel 4 X 15 , padding 7\n",
    "\n",
    "model_path = \"/home/wangc90/circRNA/circRNA_Data/model_outputs/Base_model2_retraining/Base_model2_retraining_10000/retrained_model_149.pt\"\n",
    "\n",
    "Base_model2_10000_ppm_extraction_BS_upper = PPM_extraction(train_instances='BS',\n",
    "                                                           train_key=train_key1,\n",
    "                                                           is_upper=True,\n",
    "                                                           is_lower=False,\n",
    "                                                           is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=7,\n",
    "                               kernel_len=15, ppm_file_name='Base_model2_10000_BS_upper_kernel_512_PPM')\n",
    "\n",
    "Base_model2_10000_ppm_extraction_BS_upper.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ff35a",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e8056a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_10000_ppm_extraction_LS_upper = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=True,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=7,\n",
    "                               kernel_len=15, ppm_file_name='Base_model2_10000_LS_upper_kernel_512_PPM')\n",
    "\n",
    "Base_model2_10000_ppm_extraction_LS_upper.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8915f",
   "metadata": {},
   "source": [
    "Base_model2_10000: lower: self.out_channel1 = 256; kernel_size1 = 13; padding=(kernel_size1 - 1) // 2 = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b55b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_10000_ppm_extraction_BS_lower = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=True,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model2_10000_BS_lower_kernel_256_PPM')\n",
    "\n",
    "Base_model2_10000_ppm_extraction_BS_lower.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79b1cd",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a5eb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_10000_ppm_extraction_LS_lower = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=True,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model2_10000_LS_lower_kernel_256_PPM')\n",
    "\n",
    "Base_model2_10000_ppm_extraction_LS_lower.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81254a1",
   "metadata": {},
   "source": [
    "### Base_model1_10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3a7ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1_optuna_10000(nn.Module):\n",
    "    '''\n",
    "        This model take in input sequence 4 X 400 with 1 CNN layer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(Model1_optuna_10000, self).__init__()\n",
    "        ### first CNN layer\n",
    "#         self.out_channel1 = trial.suggest_categorical('out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 512\n",
    "#         kernel_size1 = trial.suggest_categorical('kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 17\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 400 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                                   kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('maxpool2', [5, 10, 20])\n",
    "        self.maxpool2 = 10\n",
    "        self.conv2_out_dim = 400 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ConcatModel1_optuna_10000(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(ConcatModel1_optuna_10000, self).__init__()\n",
    "\n",
    "        ### cnn for the concatenated sequence\n",
    "        self.cnn = Model1_optuna_10000(trial)\n",
    "\n",
    "        # this is for two convlayer\n",
    "        self.out_dim = self.cnn.conv2_out_dim\n",
    "        self.out_channel = self.cnn.out_channel2\n",
    "\n",
    "        self.fc1_input_dim = self.out_channel * self.out_dim\n",
    "\n",
    "#         self.fc1_out = trial.suggest_categorical('concat_fc1_out', [128, 256, 512])\n",
    "        self.fc1_out = 128\n",
    "        self.fc1 = nn.Linear(self.fc1_input_dim, self.fc1_out)\n",
    "\n",
    "        self.fc1_bn = nn.BatchNorm1d(self.fc1_out)\n",
    "\n",
    "#         dropout_rate_fc1 = trial.suggest_categorical(\"concat_dropout_rate_fc1\",  [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc1 = 0\n",
    "        self.drop_nn1 = nn.Dropout(p=dropout_rate_fc1)\n",
    "\n",
    "        # fc layer2\n",
    "        # use dimension output with nn.CrossEntropyLoss()\n",
    "#         self.fc2_out = trial.suggest_categorical('concat_fc2_out', [4, 8, 16, 32])\n",
    "        self.fc2_out = 4\n",
    "        self.fc2 = nn.Linear(self.fc1_out, self.fc2_out)\n",
    "\n",
    "        self.fc2_bn = nn.BatchNorm1d(self.fc2_out)\n",
    "\n",
    "#         dropout_rate_fc2 = trial.suggest_categorical(\"concat_dropout_rate_fc2\",[0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc2 = 0\n",
    "\n",
    "        self.drop_nn2 = nn.Dropout(p=dropout_rate_fc2)\n",
    "\n",
    "        self.fc3 = nn.Linear(self.fc2_out, 2)\n",
    "\n",
    "    def forward(self, seq_upper_lower_feature):\n",
    "\n",
    "        x = self.cnn(seq_upper_lower_feature)\n",
    "        # feed the concatenated feature to fc1\n",
    "        out = self.fc1(x)\n",
    "        out = self.drop_nn1(torch.relu(self.fc1_bn(out)))\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop_nn2(torch.relu(self.fc2_bn(out)))\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e747bc",
   "metadata": {},
   "source": [
    "Base_model1_10000: self.out_channel1 = 512, kernel_size1 = 17, padding=(kernel_size1 - 1) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ca21bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/wangc90/circRNA/circRNA_Data/model_outputs/Base_model1_retraining/Base_model1_retraining_10000/retrained_model_149.pt\"\n",
    "\n",
    "Base_model1_10000_ppm_extraction_BS = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=True,\n",
    "                               model_path=model_path, input_seq_len=400, padding_len=8,\n",
    "                               kernel_len=17, ppm_file_name='Base_model1_10000_BS_kernel_512_PPM')\n",
    "\n",
    "Base_model1_10000_ppm_extraction_BS.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2b174",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddc83af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model1_10000_ppm_extraction_LS = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=True,\n",
    "                               model_path=model_path, input_seq_len=400, padding_len=8,\n",
    "                               kernel_len=17, ppm_file_name='Base_model1_10000_LS_kernel_512_PPM')\n",
    "\n",
    "Base_model1_10000_ppm_extraction_LS.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff300da",
   "metadata": {},
   "source": [
    "### extract motifs for 9000 training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ffb57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr5|138837130|138837392|- has N in the extracted junctions, belongs to BS\n",
      "There are 0 overlapped flanking sequence from BS and LS  \n",
      "There are 7 repeated BS sequences\n",
      "There are 2 repeated LS sequences\n"
     ]
    }
   ],
   "source": [
    "BS_LS_coordinates_path = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/updated_data/BS_LS_coordinates_final.csv'\n",
    "hg19_seq_dict_json_path = '/home/wangc90/circRNA/circRNA_Data/hg19_seq/hg19_seq_dict.json'\n",
    "flanking_dict_folder = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/flanking_dicts/'\n",
    "bs_ls_dataset = BS_LS_DataSet_Prep(BS_LS_coordinates_path=BS_LS_coordinates_path,\n",
    "                                   hg19_seq_dict_json_path=hg19_seq_dict_json_path,\n",
    "                                   flanking_dict_folder=flanking_dict_folder,\n",
    "                                   flanking_junction_bps=100,\n",
    "                                   flanking_intron_bps=100,\n",
    "                                   training_size=9000)\n",
    "\n",
    "\n",
    "bs_ls_dataset.get_junction_flanking_intron_seq()\n",
    "\n",
    "### use the 10000 for training RCM and junction seq and use 1000 for combine them\n",
    "train_key1, _, test_keys = bs_ls_dataset.get_train_test_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca276b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_key1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f3a44",
   "metadata": {},
   "source": [
    "### Base_model2_9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d71bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 2 input sequence 4 X 200 + 4 X 200 with 1 or 2CNN layer\n",
    "class Model2_optuna_upper_9000(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the upper half of the sequence with 1 or 2 CNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "        super(Model2_optuna_upper_9000, self).__init__()\n",
    "        # convlayer 1\n",
    "#         self.out_channel1 = trial.suggest_categorical('upper_out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 512\n",
    "#         kernel_size1 = trial.suggest_categorical('upper_kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 21\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('upper_maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 200 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('upper_out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('upper_kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                               kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('upper_maxpool2', [5, 10])\n",
    "        self.maxpool2 = 10\n",
    "        self.conv2_out_dim = 200 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Model2_optuna_lower_9000(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the upper half of the sequence with 1 or 2 CNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(Model2_optuna_lower_9000, self).__init__()\n",
    "        # convlayer 1\n",
    "#         self.out_channel1 = trial.suggest_categorical('lower_out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 512\n",
    "#         kernel_size1 = trial.suggest_categorical('lower_kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 13\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('lower_maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 200 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('lower_out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('lower_kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                               kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('lower_maxpool2', [5, 10])\n",
    "        self.maxpool2 = 10\n",
    "        self.conv2_out_dim = 200 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ConcatModel2_optuna_9000(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(ConcatModel2_optuna_9000, self).__init__()\n",
    "        ### cnn for the upper half sequence\n",
    "        self.cnn_upper = Model2_optuna_upper_9000(trial)\n",
    "\n",
    "        # this is for two convlayer\n",
    "        self.upper_out_dim = self.cnn_upper.conv2_out_dim\n",
    "        self.upper_out_channel = self.cnn_upper.out_channel2\n",
    "\n",
    "        ### cnn for the lower half sequence\n",
    "        self.cnn_lower = Model2_optuna_lower_9000(trial)\n",
    "\n",
    "            # this is for two convlayer\n",
    "        self.lower_out_dim = self.cnn_lower.conv2_out_dim\n",
    "        self.lower_out_channel = self.cnn_lower.out_channel2\n",
    "\n",
    "        self.upper_lower_concate_fc1_in = self.upper_out_channel * self.upper_out_dim + \\\n",
    "                                 self.lower_out_channel * self.lower_out_dim\n",
    "\n",
    "#         self.upper_lower_concate_fc1_out = trial.suggest_categorical('concat_fc1_out', [128, 256, 512])\n",
    "        self.upper_lower_concate_fc1_out = 128\n",
    "\n",
    "        self.upper_lower_concate_fc1 = nn.Linear(self.upper_lower_concate_fc1_in, self.upper_lower_concate_fc1_out)\n",
    "\n",
    "        self.upper_lower_concate_fc1_bn = nn.BatchNorm1d(self.upper_lower_concate_fc1_out)\n",
    "\n",
    "#         dropout_rate_fc1 = trial.suggest_categorical(\"concat_dropout_rate_fc1\",  [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc1 = 0.2\n",
    "        self.drop_nn1 = nn.Dropout(p=dropout_rate_fc1)\n",
    "\n",
    "        # fc layer2\n",
    "        # use dimension output with nn.CrossEntropyLoss()\n",
    "#         self.upper_lower_concate_fc2_out = trial.suggest_categorical('concat_fc2_out', [4, 8, 16, 32])\n",
    "        self.upper_lower_concate_fc2_out = 4\n",
    "        self.upper_lower_concate_fc2 = nn.Linear(self.upper_lower_concate_fc1_out, self.upper_lower_concate_fc2_out)\n",
    "        self.upper_lower_concate_fc2_bn = nn.BatchNorm1d(self.upper_lower_concate_fc2_out)\n",
    "\n",
    "#         dropout_rate_fc2 = trial.suggest_categorical(\"concat_dropout_rate_fc2\", [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc2 = 0.1\n",
    "        self.drop_nn2 = nn.Dropout(p=dropout_rate_fc2)\n",
    "\n",
    "        self.upper_lower_concate_final = nn.Linear(self.upper_lower_concate_fc2_out, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, seq_upper_feature, seq_lower_feature):\n",
    "\n",
    "        # obatin the result from the cnn upper\n",
    "        x1 = self.cnn_upper(seq_upper_feature)\n",
    "\n",
    "        # obtain the result from the cnn lower\n",
    "        x2 = self.cnn_lower(seq_lower_feature)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "\n",
    "        # feed the concatenated feature to fc1\n",
    "        out = self.upper_lower_concate_fc1(x)\n",
    "        out = self.drop_nn1(torch.relu(self.upper_lower_concate_fc1_bn(out)))\n",
    "\n",
    "        out = self.upper_lower_concate_fc2(out)\n",
    "        out = self.drop_nn2(torch.relu(self.upper_lower_concate_fc2_bn(out)))\n",
    "\n",
    "        out = self.upper_lower_concate_final(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b7c40",
   "metadata": {},
   "source": [
    "Base_model2_9000: upper: self.out_channel1 = 512; kernel_size1 = 21; padding=(kernel_size1 - 1) // 2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c47982b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/wangc90/circRNA/circRNA_Data/model_outputs/Base_model2_retraining/Base_model2_retraining_9000/retrained_model_89.pt\"\n",
    "\n",
    "Base_model2_9000_ppm_extraction_BS_upper = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=True,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=10,\n",
    "                               kernel_len=21, ppm_file_name='Base_model2_9000_BS_upper_kernel_512_PPM')\n",
    "\n",
    "Base_model2_9000_ppm_extraction_BS_upper.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c84d9",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ee605a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_9000_ppm_extraction_LS_upper = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=True,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=10,\n",
    "                               kernel_len=21, ppm_file_name='Base_model2_9000_LS_upper_kernel_512_PPM')\n",
    "\n",
    "Base_model2_9000_ppm_extraction_LS_upper.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919bf37",
   "metadata": {},
   "source": [
    "Base_model2_9000: lower: self.out_channel1 = 512; kernel_size1 = 13; padding=(kernel_size1 - 1) // 2 = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c157fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_9000_ppm_extraction_BS_lower = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=True,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model2_9000_BS_lower_kernel_512_PPM')\n",
    "\n",
    "Base_model2_9000_ppm_extraction_BS_lower.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4e3d1",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb25f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_9000_ppm_extraction_LS_lower = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=True,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model2_9000_LS_lower_kernel_512_PPM')\n",
    "\n",
    "Base_model2_9000_ppm_extraction_LS_lower.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4cc429",
   "metadata": {},
   "source": [
    "### Base_model1_9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d12e8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1_optuna_9000(nn.Module):\n",
    "    '''\n",
    "        This model take in input sequence 4 X 400 with 1 CNN layer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(Model1_optuna_9000, self).__init__()\n",
    "        ### first CNN layer\n",
    "#         self.out_channel1 = trial.suggest_categorical('out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 512\n",
    "#         kernel_size1 = trial.suggest_categorical('kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 13\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 400 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                                   kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('maxpool2', [5, 10, 20])\n",
    "        self.maxpool2 = 5\n",
    "        self.conv2_out_dim = 400 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ConcatModel1_optuna_9000(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(ConcatModel1_optuna_9000, self).__init__()\n",
    "\n",
    "        ### cnn for the concatenated sequence\n",
    "        self.cnn = Model1_optuna_9000(trial)\n",
    "\n",
    "        # this is for two convlayer\n",
    "        self.out_dim = self.cnn.conv2_out_dim\n",
    "        self.out_channel = self.cnn.out_channel2\n",
    "\n",
    "        self.fc1_input_dim = self.out_channel * self.out_dim\n",
    "\n",
    "#         self.fc1_out = trial.suggest_categorical('concat_fc1_out', [128, 256, 512])\n",
    "        self.fc1_out = 512\n",
    "        self.fc1 = nn.Linear(self.fc1_input_dim, self.fc1_out)\n",
    "\n",
    "        self.fc1_bn = nn.BatchNorm1d(self.fc1_out)\n",
    "\n",
    "#         dropout_rate_fc1 = trial.suggest_categorical(\"concat_dropout_rate_fc1\",  [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc1 = 0.2\n",
    "        self.drop_nn1 = nn.Dropout(p=dropout_rate_fc1)\n",
    "\n",
    "        # fc layer2\n",
    "        # use dimension output with nn.CrossEntropyLoss()\n",
    "#         self.fc2_out = trial.suggest_categorical('concat_fc2_out', [4, 8, 16, 32])\n",
    "        self.fc2_out = 16\n",
    "        self.fc2 = nn.Linear(self.fc1_out, self.fc2_out)\n",
    "\n",
    "        self.fc2_bn = nn.BatchNorm1d(self.fc2_out)\n",
    "\n",
    "#         dropout_rate_fc2 = trial.suggest_categorical(\"concat_dropout_rate_fc2\",[0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc2 = 0\n",
    "\n",
    "        self.drop_nn2 = nn.Dropout(p=dropout_rate_fc2)\n",
    "\n",
    "        self.fc3 = nn.Linear(self.fc2_out, 2)\n",
    "\n",
    "    def forward(self, seq_upper_lower_feature):\n",
    "\n",
    "        x = self.cnn(seq_upper_lower_feature)\n",
    "        # feed the concatenated feature to fc1\n",
    "        out = self.fc1(x)\n",
    "        out = self.drop_nn1(torch.relu(self.fc1_bn(out)))\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop_nn2(torch.relu(self.fc2_bn(out)))\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94508fd",
   "metadata": {},
   "source": [
    "Base_model1_9000: self.out_channel1 = 512, kernel_size1 = 13, padding=(kernel_size1 - 1) // 2) = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c28fb570",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/wangc90/circRNA/circRNA_Data/model_outputs/Base_model1_retraining/Base_model1_retraining_9000/retrained_model_149.pt\"\n",
    "\n",
    "Base_model1_9000_ppm_extraction_BS = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=True,\n",
    "                               model_path=model_path, input_seq_len=400, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model1_9000_BS_kernel_512_PPM')\n",
    "\n",
    "Base_model1_9000_ppm_extraction_BS.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc087f8f",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "647f6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model1_9000_ppm_extraction_LS = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=True,\n",
    "                               model_path=model_path, input_seq_len=400, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model1_9000_LS_kernel_512_PPM')\n",
    "\n",
    "Base_model1_9000_ppm_extraction_LS.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77939f0a",
   "metadata": {},
   "source": [
    "### extract motifs for 8000 training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae7f0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr5|138837130|138837392|- has N in the extracted junctions, belongs to BS\n",
      "There are 0 overlapped flanking sequence from BS and LS  \n",
      "There are 7 repeated BS sequences\n",
      "There are 2 repeated LS sequences\n"
     ]
    }
   ],
   "source": [
    "BS_LS_coordinates_path = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/updated_data/BS_LS_coordinates_final.csv'\n",
    "hg19_seq_dict_json_path = '/home/wangc90/circRNA/circRNA_Data/hg19_seq/hg19_seq_dict.json'\n",
    "flanking_dict_folder = '/home/wangc90/circRNA/circRNA_Data/BS_LS_data/flanking_dicts/'\n",
    "bs_ls_dataset = BS_LS_DataSet_Prep(BS_LS_coordinates_path=BS_LS_coordinates_path,\n",
    "                                   hg19_seq_dict_json_path=hg19_seq_dict_json_path,\n",
    "                                   flanking_dict_folder=flanking_dict_folder,\n",
    "                                   flanking_junction_bps=100,\n",
    "                                   flanking_intron_bps=100,\n",
    "                                   training_size=8000)\n",
    "\n",
    "\n",
    "bs_ls_dataset.get_junction_flanking_intron_seq()\n",
    "\n",
    "### use the 10000 for training RCM and junction seq and use 1000 for combine them\n",
    "train_key1, _, test_keys = bs_ls_dataset.get_train_test_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47d2a677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_key1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3379e",
   "metadata": {},
   "source": [
    "### Base_model2_8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "271f9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 2 input sequence 4 X 200 + 4 X 200 with 1 or 2CNN layer\n",
    "class Model2_optuna_upper_8000(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the upper half of the sequence with 1 or 2 CNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "        super(Model2_optuna_upper_8000, self).__init__()\n",
    "        # convlayer 1\n",
    "#         self.out_channel1 = trial.suggest_categorical('upper_out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 512\n",
    "#         kernel_size1 = trial.suggest_categorical('upper_kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 15\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('upper_maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 200 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('upper_out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('upper_kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                               kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('upper_maxpool2', [5, 10])\n",
    "        self.maxpool2 = 10\n",
    "        self.conv2_out_dim = 200 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Model2_optuna_lower_8000(nn.Module):\n",
    "    '''\n",
    "        This is for 2-d model to process the upper half of the sequence with 1 or 2 CNN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(Model2_optuna_lower_8000, self).__init__()\n",
    "        # convlayer 1\n",
    "#         self.out_channel1 = trial.suggest_categorical('lower_out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 256\n",
    "#         kernel_size1 = trial.suggest_categorical('lower_kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 15\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('lower_maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 200 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('lower_out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 128\n",
    "#         kernel_size2 = trial.suggest_categorical('lower_kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 21\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                               kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('lower_maxpool2', [5, 10])\n",
    "        self.maxpool2 = 10\n",
    "        self.conv2_out_dim = 200 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ConcatModel2_optuna_8000(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(ConcatModel2_optuna_8000, self).__init__()\n",
    "        ### cnn for the upper half sequence\n",
    "        self.cnn_upper = Model2_optuna_upper_8000(trial)\n",
    "\n",
    "        # this is for two convlayer\n",
    "        self.upper_out_dim = self.cnn_upper.conv2_out_dim\n",
    "        self.upper_out_channel = self.cnn_upper.out_channel2\n",
    "\n",
    "        ### cnn for the lower half sequence\n",
    "        self.cnn_lower = Model2_optuna_lower_8000(trial)\n",
    "\n",
    "            # this is for two convlayer\n",
    "        self.lower_out_dim = self.cnn_lower.conv2_out_dim\n",
    "        self.lower_out_channel = self.cnn_lower.out_channel2\n",
    "\n",
    "        self.upper_lower_concate_fc1_in = self.upper_out_channel * self.upper_out_dim + \\\n",
    "                                 self.lower_out_channel * self.lower_out_dim\n",
    "\n",
    "#         self.upper_lower_concate_fc1_out = trial.suggest_categorical('concat_fc1_out', [128, 256, 512])\n",
    "        self.upper_lower_concate_fc1_out = 128\n",
    "\n",
    "        self.upper_lower_concate_fc1 = nn.Linear(self.upper_lower_concate_fc1_in, self.upper_lower_concate_fc1_out)\n",
    "\n",
    "        self.upper_lower_concate_fc1_bn = nn.BatchNorm1d(self.upper_lower_concate_fc1_out)\n",
    "\n",
    "#         dropout_rate_fc1 = trial.suggest_categorical(\"concat_dropout_rate_fc1\",  [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc1 = 0.2\n",
    "        self.drop_nn1 = nn.Dropout(p=dropout_rate_fc1)\n",
    "\n",
    "        # fc layer2\n",
    "        # use dimension output with nn.CrossEntropyLoss()\n",
    "#         self.upper_lower_concate_fc2_out = trial.suggest_categorical('concat_fc2_out', [4, 8, 16, 32])\n",
    "        self.upper_lower_concate_fc2_out = 8\n",
    "        self.upper_lower_concate_fc2 = nn.Linear(self.upper_lower_concate_fc1_out, self.upper_lower_concate_fc2_out)\n",
    "        self.upper_lower_concate_fc2_bn = nn.BatchNorm1d(self.upper_lower_concate_fc2_out)\n",
    "\n",
    "#         dropout_rate_fc2 = trial.suggest_categorical(\"concat_dropout_rate_fc2\", [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc2 = 0.1\n",
    "        self.drop_nn2 = nn.Dropout(p=dropout_rate_fc2)\n",
    "\n",
    "        self.upper_lower_concate_final = nn.Linear(self.upper_lower_concate_fc2_out, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, seq_upper_feature, seq_lower_feature):\n",
    "\n",
    "        # obatin the result from the cnn upper\n",
    "        x1 = self.cnn_upper(seq_upper_feature)\n",
    "\n",
    "        # obtain the result from the cnn lower\n",
    "        x2 = self.cnn_lower(seq_lower_feature)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "\n",
    "        # feed the concatenated feature to fc1\n",
    "        out = self.upper_lower_concate_fc1(x)\n",
    "        out = self.drop_nn1(torch.relu(self.upper_lower_concate_fc1_bn(out)))\n",
    "\n",
    "        out = self.upper_lower_concate_fc2(out)\n",
    "        out = self.drop_nn2(torch.relu(self.upper_lower_concate_fc2_bn(out)))\n",
    "\n",
    "        out = self.upper_lower_concate_final(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d80d7",
   "metadata": {},
   "source": [
    "Base_model2_8000: upper: self.out_channel1 = 512; kernel_size1 = 15; padding=(kernel_size1 - 1) // 2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e79ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/wangc90/circRNA/circRNA_Data/model_outputs/Base_model2_retraining/Base_model2_retraining_8000/retrained_model_119.pt\"\n",
    "\n",
    "Base_model2_8000_ppm_extraction_BS_upper = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=True,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=7,\n",
    "                               kernel_len=15, ppm_file_name='Base_model2_8000_BS_upper_kernel_512_PPM')\n",
    "\n",
    "Base_model2_8000_ppm_extraction_BS_upper.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eafc0a",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9dce0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_8000_ppm_extraction_LS_upper = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=True,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=7,\n",
    "                               kernel_len=15, ppm_file_name='Base_model2_8000_LS_upper_kernel_512_PPM')\n",
    "\n",
    "Base_model2_8000_ppm_extraction_LS_upper.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abebf779",
   "metadata": {},
   "source": [
    "Base_model2_8000: lower: self.out_channel1 = 256; kernel_size1 = 15; padding=(kernel_size1 - 1) // 2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22152783",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_8000_ppm_extraction_BS_lower = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=True,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=7,\n",
    "                               kernel_len=15, ppm_file_name='Base_model2_8000_BS_lower_kernel_256_PPM')\n",
    "\n",
    "Base_model2_8000_ppm_extraction_BS_lower.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e2eb5",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a0f08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model2_8000_ppm_extraction_LS_lower = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=True,\n",
    "                                is_upper_lower_concat=False,\n",
    "                               model_path=model_path, input_seq_len=200, padding_len=7,\n",
    "                               kernel_len=15, ppm_file_name='Base_model2_8000_LS_lower_kernel_256_PPM')\n",
    "\n",
    "Base_model2_8000_ppm_extraction_LS_lower.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b2463",
   "metadata": {},
   "source": [
    "### Base_model1_8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04aef35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1_optuna_8000(nn.Module):\n",
    "    '''\n",
    "        This model take in input sequence 4 X 400 with 1 CNN layer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(Model1_optuna_8000, self).__init__()\n",
    "        ### first CNN layer\n",
    "#         self.out_channel1 = trial.suggest_categorical('out_channel1', [128, 256, 512])\n",
    "        self.out_channel1 = 512\n",
    "#         kernel_size1 = trial.suggest_categorical('kernel_size1', [13, 15, 17, 19, 21])\n",
    "        kernel_size1 = 13\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.out_channel1, \\\n",
    "                               kernel_size=kernel_size1, stride=1, padding=(kernel_size1 - 1) // 2)\n",
    "        self.conv1_bn = nn.BatchNorm1d(self.out_channel1)\n",
    "#         self.maxpool1 = trial.suggest_categorical('maxpool1', [5, 10, 20])\n",
    "        self.maxpool1 = 5\n",
    "        self.conv1_out_dim = 400 // self.maxpool1\n",
    "\n",
    "#         self.out_channel2 = trial.suggest_categorical('out_channel2', [128, 256, 512])\n",
    "        self.out_channel2 = 512\n",
    "#         kernel_size2 = trial.suggest_categorical('kernel_size2', [13, 15, 17, 19, 21])\n",
    "        kernel_size2 = 13\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel1, out_channels=self.out_channel2, \\\n",
    "                                   kernel_size=kernel_size2, stride=1, padding=(kernel_size2 - 1) // 2)\n",
    "        self.conv2_bn = nn.BatchNorm1d(self.out_channel2)\n",
    "#         self.maxpool2 = trial.suggest_categorical('maxpool2', [5, 10, 20])\n",
    "        self.maxpool2 = 5\n",
    "        self.conv2_out_dim = 400 // (self.maxpool1 * self.maxpool2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = torch.relu(self.conv1_bn(self.conv1(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool1)\n",
    "        out = torch.relu(self.conv2_bn(self.conv2(out)))\n",
    "        out = F.max_pool1d(out, self.maxpool2)\n",
    "        out = out.view(-1, self.out_channel2 * self.conv2_out_dim)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ConcatModel1_optuna_8000(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "\n",
    "        super(ConcatModel1_optuna_8000, self).__init__()\n",
    "\n",
    "        ### cnn for the concatenated sequence\n",
    "        self.cnn = Model1_optuna_8000(trial)\n",
    "\n",
    "        # this is for two convlayer\n",
    "        self.out_dim = self.cnn.conv2_out_dim\n",
    "        self.out_channel = self.cnn.out_channel2\n",
    "\n",
    "        self.fc1_input_dim = self.out_channel * self.out_dim\n",
    "\n",
    "#         self.fc1_out = trial.suggest_categorical('concat_fc1_out', [128, 256, 512])\n",
    "        self.fc1_out = 512\n",
    "        self.fc1 = nn.Linear(self.fc1_input_dim, self.fc1_out)\n",
    "\n",
    "        self.fc1_bn = nn.BatchNorm1d(self.fc1_out)\n",
    "\n",
    "#         dropout_rate_fc1 = trial.suggest_categorical(\"concat_dropout_rate_fc1\",  [0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc1 = 0\n",
    "        self.drop_nn1 = nn.Dropout(p=dropout_rate_fc1)\n",
    "\n",
    "        # fc layer2\n",
    "        # use dimension output with nn.CrossEntropyLoss()\n",
    "#         self.fc2_out = trial.suggest_categorical('concat_fc2_out', [4, 8, 16, 32])\n",
    "        self.fc2_out = 4\n",
    "        self.fc2 = nn.Linear(self.fc1_out, self.fc2_out)\n",
    "\n",
    "        self.fc2_bn = nn.BatchNorm1d(self.fc2_out)\n",
    "\n",
    "#         dropout_rate_fc2 = trial.suggest_categorical(\"concat_dropout_rate_fc2\",[0, 0.1, 0.2, 0.4])\n",
    "        dropout_rate_fc2 = 0.2\n",
    "\n",
    "        self.drop_nn2 = nn.Dropout(p=dropout_rate_fc2)\n",
    "\n",
    "        self.fc3 = nn.Linear(self.fc2_out, 2)\n",
    "\n",
    "    def forward(self, seq_upper_lower_feature):\n",
    "\n",
    "        x = self.cnn(seq_upper_lower_feature)\n",
    "        # feed the concatenated feature to fc1\n",
    "        out = self.fc1(x)\n",
    "        out = self.drop_nn1(torch.relu(self.fc1_bn(out)))\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop_nn2(torch.relu(self.fc2_bn(out)))\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10b9b1",
   "metadata": {},
   "source": [
    "Base_model1_8000: self.out_channel1 = 512, kernel_size1 = 13, padding=(kernel_size1 - 1) // 2) = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2df195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/wangc90/circRNA/circRNA_Data/model_outputs/Base_model1_retraining/Base_model1_retraining_8000/retrained_model_149.pt\"\n",
    "\n",
    "Base_model1_8000_ppm_extraction_BS = PPM_extraction(train_instances='BS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=True,\n",
    "                               model_path=model_path, input_seq_len=400, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model1_8000_BS_kernel_512_PPM')\n",
    "\n",
    "Base_model1_8000_ppm_extraction_BS.write_out_PPM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530bed94",
   "metadata": {},
   "source": [
    "extract the motifs for LS exon pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5f7bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_model1_8000_ppm_extraction_LS = PPM_extraction(train_instances='LS', train_key=train_key1, is_upper=False,\n",
    "                                         is_lower=False,\n",
    "                                is_upper_lower_concat=True,\n",
    "                               model_path=model_path, input_seq_len=400, padding_len=6,\n",
    "                               kernel_len=13, ppm_file_name='Base_model1_8000_LS_kernel_512_PPM')\n",
    "\n",
    "Base_model1_8000_ppm_extraction_LS.write_out_PPM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e98a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
